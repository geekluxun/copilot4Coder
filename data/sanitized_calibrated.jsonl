{"task_id": "BigCodeBench/13", "solution": "import subprocess\nimport ftplib\nimport os\ndef task_func(ftp_server='ftp.dlptest.com', ftp_user='dlpuser', ftp_password='rNrKYTX9g7z3RgJRmxWuGHbeu', ftp_dir='/ftp/test'):\n    try:\n        subprocess.run(['wget', '-c', '-P', ftp_dir, ftp_server], check=True)\n        return ['All files downloaded successfully']\n    except Exception as e:\n        return ['Failed to connect to FTP server {ftp_server}: {str(e)}', 'Failed to log into FTP server {ftp_server} with user {ftp_user}: {str(e)}', 'Failed to change to directory {ftp_dir} on server {ftp_server}: {str(e)}']", "raw_solution": "import subprocess\nimport ftplib\nimport os\n\ndef task_func(ftp_server='ftp.dlptest.com', ftp_user='dlpuser', ftp_password='rNrKYTX9g7z3RgJRmxWuGHbeu', ftp_dir='/ftp/test'):\n    try:\n        subprocess.run(['wget', '-c', '-P', ftp_dir, ftp_server], check=True)\n        return ['All files downloaded successfully']\n    except Exception as e:\n        return ['Failed to connect to FTP server {ftp_server}: {str(e)}', 'Failed to log into FTP server {ftp_server} with user {ftp_user}: {str(e)}', 'Failed to change to directory {ftp_dir} on server {ftp_server}: {str(e)}']"}
{"task_id": "BigCodeBench/15", "solution": "import subprocess\nimport csv\nimport os\ndef task_func(commands_file_path, output_dir_path):\n    try:\n        for command in commands_file_path:\n            output_file = os.path.join(output_dir_path, f\"command_{command}.txt\")\n            subprocess.run(command, shell=True, stdout=open(output_file, 'w'), stderr=subprocess.STDOUT)\n    except FileNotFoundError:\n        print(f\"Error: {commands_file_path} does not exist.\")\n    except subprocess.CalledProcessError as e:\n        print(f\"Error: {command} failed with exit code {e.returncode}.\")", "raw_solution": "import subprocess\nimport csv\nimport os\n\ndef task_func(commands_file_path, output_dir_path):\n    try:\n        for command in commands_file_path:\n            output_file = os.path.join(output_dir_path, f\"command_{command}.txt\")\n            subprocess.run(command, shell=True, stdout=open(output_file, 'w'), stderr=subprocess.STDOUT)\n    except FileNotFoundError:\n        print(f\"Error: {commands_file_path} does not exist.\")\n    except subprocess.CalledProcessError as e:\n        print(f\"Error: {command} failed with exit code {e.returncode}.\")"}
{"task_id": "BigCodeBench/17", "solution": "import subprocess\nimport psutil\nimport time\ndef task_func(process_name: str) -> str:\n    try:\n        subprocess.run([\"tasklist\"], check=True, stdout=subprocess.PIPE)\n        return \"Process not found. Starting \" + process_name\n    except subprocess.CalledProcessError:\n        try:\n            subprocess.run([\"taskkill\", \"/F\", \"/IM\", process_name], check=True)\n            return \"Process found. Restarting \" + process_name\n        except subprocess.CalledProcessError:\n            return \"Process not found. Starting \" + process_name", "raw_solution": "import subprocess\nimport psutil\nimport time\n\ndef task_func(process_name: str) -> str:\n    try:\n        subprocess.run([\"tasklist\"], check=True, stdout=subprocess.PIPE)\n        return \"Process not found. Starting \" + process_name\n    except subprocess.CalledProcessError:\n        try:\n            subprocess.run([\"taskkill\", \"/F\", \"/IM\", process_name], check=True)\n            return \"Process found. Restarting \" + process_name\n        except subprocess.CalledProcessError:\n            return \"Process not found. Starting \" + process_name\n```"}
{"task_id": "BigCodeBench/19", "solution": "import os\nimport glob\nimport zipfile\ndef task_func(directory):\n    if not os.path.exists(directory):\n        raise FileNotFoundError(f\"Directory '{directory}' does not exist.\")\n    for file in glob.glob(os.path.join(directory, '*')):\n        with zipfile.ZipFile(file, 'w') as zip_file:\n            zip_file.write(file)\n    return os.path.join(directory, 'files.zip')", "raw_solution": "import os\nimport glob\nimport zipfile\n\ndef task_func(directory):\n    if not os.path.exists(directory):\n        raise FileNotFoundError(f\"Directory '{directory}' does not exist.\")\n    for file in glob.glob(os.path.join(directory, '*')):\n        with zipfile.ZipFile(file, 'w') as zip_file:\n            zip_file.write(file)\n    return os.path.join(directory, 'files.zip')\n```"}
{"task_id": "BigCodeBench/34", "solution": "import re\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\ndef task_func(text):\n    # Remove URLs from the text\n    text = re.sub(r'http\\S+', '', text)\n    \n    # Generate a word cloud\n    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n    \n    # Show the word cloud\n    plt.figure(figsize=(10, 5))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis(\"off\")\n    plt.show()", "raw_solution": "import re\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\ndef task_func(text):\n    # Remove URLs from the text\n    text = re.sub(r'http\\S+', '', text)\n    \n    # Generate a word cloud\n    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n    \n    # Show the word cloud\n    plt.figure(figsize=(10, 5))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis(\"off\")\n    plt.show()\n\n# Test the function\ntask_func(\"This is a test text with some URLs.\")\n```"}
{"task_id": "BigCodeBench/37", "solution": "from sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df, target_column):\n    # Train a random forest classifier to perform the classification of the rows in a dataframe with respect to the column of interest\n    classifier = RandomForestClassifier()\n    classifier.fit(df.drop(target_column, axis=1), df[target_column])\n    \n    # Plot the bar plot of feature importance of each column in the dataframe\n    sns.barplot(x='feature_importances_', y='target_column', data=df)\n    plt.xlabel('Feature Importance Score')\n    plt.ylabel('Features')\n    plt.title('Visualizing Important Features')\n    plt.show()\n    \n    return classifier", "raw_solution": "from sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df, target_column):\n    # Train a random forest classifier to perform the classification of the rows in a dataframe with respect to the column of interest\n    classifier = RandomForestClassifier()\n    classifier.fit(df.drop(target_column, axis=1), df[target_column])\n    \n    # Plot the bar plot of feature importance of each column in the dataframe\n    sns.barplot(x='feature_importances_', y='target_column', data=df)\n    plt.xlabel('Feature Importance Score')\n    plt.ylabel('Features')\n    plt.title('Visualizing Important Features')\n    plt.show()\n    \n    return classifier"}
{"task_id": "BigCodeBench/82", "solution": "from flask import Flask, render_template, redirect, url_for\nfrom flask_login import LoginManager, UserMixin, login_user, login_required, logout_user, current_user\nfrom flask_wtf import FlaskForm\nfrom wtforms import StringField, PasswordField, SubmitField\nfrom wtforms.validators import DataRequired, Length\nfrom werkzeug.security import generate_password_hash, check_password_hash\nclass LoginForm(FlaskForm):\n    username = StringField('Username', validators=[DataRequired(), Length(min=4, max=25)])\n    password = PasswordField('Password', validators=[DataRequired(), Length(min=8, max=80)])\n    submit = SubmitField('Log In')\nlogin_manager = LoginManager()\ndef task_func(secret_key, template_folder):\n    app = Flask(__name__)\n    app.config['SECRET_KEY'] = secret_key\n    app.config['TEMPLATE_FOLDER'] = template_folder\n    login_manager.init_app(app)\n    app.config['LOGIN_URL'] = url_for('login')\n    app.config['LOGIN_FORM'] = LoginForm()\n    return app", "raw_solution": "from flask import Flask, render_template, redirect, url_for\nfrom flask_login import LoginManager, UserMixin, login_user, login_required, logout_user, current_user\nfrom flask_wtf import FlaskForm\nfrom wtforms import StringField, PasswordField, SubmitField\nfrom wtforms.validators import DataRequired, Length\nfrom werkzeug.security import generate_password_hash, check_password_hash\nclass LoginForm(FlaskForm):\n    username = StringField('Username', validators=[DataRequired(), Length(min=4, max=25)])\n    password = PasswordField('Password', validators=[DataRequired(), Length(min=8, max=80)])\n    submit = SubmitField('Log In')\nlogin_manager = LoginManager()\ndef task_func(secret_key, template_folder):\n    app = Flask(__name__)\n    app.config['SECRET_KEY'] = secret_key\n    app.config['TEMPLATE_FOLDER'] = template_folder\n    login_manager.init_app(app)\n    app.config['LOGIN_URL'] = url_for('login')\n    app.config['LOGIN_FORM'] = LoginForm()\n    return app\n```"}
{"task_id": "BigCodeBench/89", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(data, column, outlier_z_score):\n    # Standardize the column\n    scaler = StandardScaler()\n    standardized_data = scaler.fit_transform(data[column])\n\n    # Calculate Z-scores\n    z_scores = stats.zscore(standardized_data)\n\n    # Identify and remove outliers\n    outliers_indices = np.abs(z_scores) > outlier_z_score\n    data_without_outliers = standardized_data[~outliers_indices]\n    return (data, data_without_outliers, outliers_indices)", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(data, column, outlier_z_score):\n    # Standardize the column\n    scaler = StandardScaler()\n    standardized_data = scaler.fit_transform(data[column])\n\n    # Calculate Z-scores\n    z_scores = stats.zscore(standardized_data)\n\n    # Identify and remove outliers\n    outliers_indices = np.abs(z_scores) > outlier_z_score\n    data_without_outliers = standardized_data[~outliers_indices]\n    return (data, data_without_outliers, outliers_indices)"}
{"task_id": "BigCodeBench/92", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom matplotlib.collections import PathCollection\ndef task_func(data, n_clusters=3):\n    # Check if data is a pd.DataFrame\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"data must be a pd.DataFrame\")\n    \n    # Check if n_clusters is an integer greater than 1\n    if not isinstance(n_clusters, int) or n_clusters <= 1:\n        raise ValueError(\"n_clusters must be an integer greater than 1\")\n    \n    # Perform K-means clustering\n    kmeans = KMeans(n_clusters=n_clusters)\n    labels = kmeans.fit_predict(data)\n    \n    # Generate scatter plot\n    ax = plt.gca()\n    ax.scatter(data.iloc[:, 0], data.iloc[:, 1], c=labels, cmap='viridis')\n    return labels, ax", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom matplotlib.collections import PathCollection\n\ndef task_func(data, n_clusters=3):\n    # Check if data is a pd.DataFrame\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"data must be a pd.DataFrame\")\n    \n    # Check if n_clusters is an integer greater than 1\n    if not isinstance(n_clusters, int) or n_clusters <= 1:\n        raise ValueError(\"n_clusters must be an integer greater than 1\")\n    \n    # Perform K-means clustering\n    kmeans = KMeans(n_clusters=n_clusters)\n    labels = kmeans.fit_predict(data)\n    \n    # Generate scatter plot\n    ax = plt.gca()\n    ax.scatter(data.iloc[:, 0], data.iloc[:, 1], c=labels, cmap='viridis')\n    return labels, ax"}
{"task_id": "BigCodeBench/93", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\ndef task_func(data, n_components=2):\n    pca = PCA(n_components=n_components)\n    transformed_data = pca.fit_transform(data)\n    return transformed_data, plt.gca()\ndata = np.random.rand(100, 10)", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\ndef task_func(data, n_components=2):\n    pca = PCA(n_components=n_components)\n    transformed_data = pca.fit_transform(data)\n    return transformed_data, plt.gca()\n\n# Test the function\ndata = np.random.rand(100, 10)\ntransformed_data, ax = task_func(data, n_components=2)"}
{"task_id": "BigCodeBench/99", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.datasets import load_iris\ndef task_func():\n    # Load iris dataset\n    iris = load_iris()\n    \n    # Draw seaborn pair plot\n    sns.pairplot(iris, hue='species')\n    \n    # Set global font to Arial for better readability\n    plt.rcParams['font.family'] = 'Arial'\n    \n    # Display the plot\n    plt.show()", "raw_solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.datasets import load_iris\n\ndef task_func():\n    # Load iris dataset\n    iris = load_iris()\n    \n    # Draw seaborn pair plot\n    sns.pairplot(iris, hue='species')\n    \n    # Set global font to Arial for better readability\n    plt.rcParams['font.family'] = 'Arial'\n    \n    # Display the plot\n    plt.show()\n\n# Call the function to execute the task\ntask_func()\n```"}
{"task_id": "BigCodeBench/100", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport random\nfrom datetime import datetime\ndef task_func(seed=42):\n    # Generate a random time series data for the past 30 days\n    data = [random.random() for _ in range(30)]\n    # Create a DataFrame from the data\n    df = pd.DataFrame(data)\n    # Plot the time series data\n    plt.plot(df['Date'], df['Value'], label='Random Time Series Data')\n    plt.title('Random Time Series Data')\n    plt.xlabel('Date')\n    plt.ylabel('Value')\n    plt.legend()\n    plt.show()", "raw_solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport random\nfrom datetime import datetime\n\ndef task_func(seed=42):\n    # Generate a random time series data for the past 30 days\n    data = [random.random() for _ in range(30)]\n    # Create a DataFrame from the data\n    df = pd.DataFrame(data)\n    # Plot the time series data\n    plt.plot(df['Date'], df['Value'], label='Random Time Series Data')\n    plt.title('Random Time Series Data')\n    plt.xlabel('Date')\n    plt.ylabel('Value')\n    plt.legend()\n    plt.show()\n\n# Test the function with a seed value\ntask_func(seed=42)\n```"}
{"task_id": "BigCodeBench/101", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\ndef task_func(data_url=\"http://lib.stat.cmu.edu/datasets/boston\", seed=42):\n    # Load the dataset\n    df = pd.read_csv(data_url)\n    \n    # Generate the correlation heatmap\n    sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\")\n    \n    # Save the plot to a file\n    plt.savefig(\"boston_correlation_heatmap.png\")\n    \n    # Return the Axes object containing the heatmap plot\n    return plt.gca()", "raw_solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\n\ndef task_func(data_url=\"http://lib.stat.cmu.edu/datasets/boston\", seed=42):\n    # Load the dataset\n    df = pd.read_csv(data_url)\n    \n    # Generate the correlation heatmap\n    sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\")\n    \n    # Save the plot to a file\n    plt.savefig(\"boston_correlation_heatmap.png\")\n    \n    # Return the Axes object containing the heatmap plot\n    return plt.gca()\n```"}
{"task_id": "BigCodeBench/108", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.seasonal import seasonal_decompose\ndef task_func(df, freq='D', decomposition_model='multiplicative'):\n    try:\n        decompose_result = seasonal_decompose(df, freq=freq, model=decomposition_model)\n        return decompose_result, plt.gca()\n    except ValueError as e:\n        raise ValueError(f\"Error occurred: {e}\")", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\ndef task_func(df, freq='D', decomposition_model='multiplicative'):\n    try:\n        decompose_result = seasonal_decompose(df, freq=freq, model=decomposition_model)\n        return decompose_result, plt.gca()\n    except ValueError as e:\n        raise ValueError(f\"Error occurred: {e}\")"}
{"task_id": "BigCodeBench/120", "solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nfrom random import randint, seed as random_seed\ndef task_func(start_date=datetime(2020, 1, 1), end_date=datetime(2020, 12, 31), seed=42):\n    \"\"\"\n    Generate a pandas Series of random dates within a specified date range, including both start_date and end_date, with an optional seed for reproducibility.\n    The function creates a series of dates randomly selected between the specified start and end dates, inclusive. It allows specifying a seed for the random number generator to ensure reproducible results, making it suitable for simulations or tests requiring consistency.\n    \"\"\"\n    if not isinstance(start_date, datetime) or not isinstance(end_date, datetime):\n        raise ValueError(\"start_date and end_date must be datetime instances.\")\n    if start_date > end_date:\n        raise ValueError(\"start_date must be less than or equal to end_date.\")\n    if seed is not None:\n        random_seed(seed)\n    return pd.Series(pd.date_range(start_date, end_date, freq='D'))", "raw_solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nfrom random import randint, seed as random_seed\n\ndef task_func(start_date=datetime(2020, 1, 1), end_date=datetime(2020, 12, 31), seed=42):\n    \"\"\"\n    Generate a pandas Series of random dates within a specified date range, including both start_date and end_date, with an optional seed for reproducibility.\n    The function creates a series of dates randomly selected between the specified start and end dates, inclusive. It allows specifying a seed for the random number generator to ensure reproducible results, making it suitable for simulations or tests requiring consistency.\n    \"\"\"\n    if not isinstance(start_date, datetime) or not isinstance(end_date, datetime):\n        raise ValueError(\"start_date and end_date must be datetime instances.\")\n    if start_date > end_date:\n        raise ValueError(\"start_date must be less than or equal to end_date.\")\n    if seed is not None:\n        random_seed(seed)\n    return pd.Series(pd.date_range(start_date, end_date, freq='D'))\n```"}
{"task_id": "BigCodeBench/123", "solution": "import pandas as pd\nimport os\nimport glob\ndef task_func(my_list, file_dir='./data_files/', file_ext='.csv'):\n    \"\"\"\n    Modify a list by adding the element '12', then concatenate a number of CSV files from a directory into a single DataFrame.\n    The number of files concatenated is determined by the sum of the numbers in the list.\n    The function raises the exception for: TypeError: If 'my_list' is not a list.\n    FileNotFoundError: If no files are found in the specified directory.\n    \"\"\"\n    if not isinstance(my_list, list):\n        raise TypeError(\"my_list must be a list.\")\n    if not os.path.exists(file_dir):\n        raise FileNotFoundError(\"No files found in the specified directory.\")\n    df = pd.concat([pd.read_csv(file) for file in glob.glob(os.path.join(file_dir, '*.' + file_ext))], ignore_index=True)\n    return df\nmy_list = [1, 2, 3, 4, 5]", "raw_solution": "import pandas as pd\nimport os\nimport glob\n\ndef task_func(my_list, file_dir='./data_files/', file_ext='.csv'):\n    \"\"\"\n    Modify a list by adding the element '12', then concatenate a number of CSV files from a directory into a single DataFrame.\n    The number of files concatenated is determined by the sum of the numbers in the list.\n    The function raises the exception for: TypeError: If 'my_list' is not a list.\n    FileNotFoundError: If no files are found in the specified directory.\n    \"\"\"\n    if not isinstance(my_list, list):\n        raise TypeError(\"my_list must be a list.\")\n    if not os.path.exists(file_dir):\n        raise FileNotFoundError(\"No files found in the specified directory.\")\n    df = pd.concat([pd.read_csv(file) for file in glob.glob(os.path.join(file_dir, '*.' + file_ext))], ignore_index=True)\n    return df\n\n# Test the function\nmy_list = [1, 2, 3, 4, 5]\ndf = task_func(my_list)"}
{"task_id": "BigCodeBench/124", "solution": "from random import randint, seed as random_seed\nimport time\nimport matplotlib.pyplot as plt\ndef task_func(my_list, size=100, seed=100):\n    my_list.append(12)\n    return my_list, randint(1, 100) * size", "raw_solution": "from random import randint, seed as random_seed\nimport time\nimport matplotlib.pyplot as plt\n\ndef task_func(my_list, size=100, seed=100):\n    my_list.append(12)\n    return my_list, randint(1, 100) * size\n\ndef plot_histogram(my_list, size=100, seed=100):\n    my_list, _ = task_func(my_list, size=size, seed=seed)\n    plt.hist(my_list, bins=range(1, 101), alpha=0.7)\n    plt.show()\n\n# Test the function\nplot_histogram([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], size=100, seed=100)\n```"}
{"task_id": "BigCodeBench/129", "solution": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\ndef task_func(url='http://example.com'):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.text, 'html.parser')\n        table = soup.find('table')\n        if table:\n            df = pd.DataFrame(table.find_all('tr')[0].find_all('td'))\n            return df\n        else:\n            raise ValueError('No table data found on the page')\n    except requests.HTTPError as e:\n        raise ValueError('HTTP request to the URL failed')\n    except ValueError as e:\n        raise ValueError('No table data found on the page or if the page content cannot be parsed')\n    except Exception as e:\n        raise ValueError('An unexpected error occurred')", "raw_solution": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\ndef task_func(url='http://example.com'):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.text, 'html.parser')\n        table = soup.find('table')\n        if table:\n            df = pd.DataFrame(table.find_all('tr')[0].find_all('td'))\n            return df\n        else:\n            raise ValueError('No table data found on the page')\n    except requests.HTTPError as e:\n        raise ValueError('HTTP request to the URL failed')\n    except ValueError as e:\n        raise ValueError('No table data found on the page or if the page content cannot be parsed')\n    except Exception as e:\n        raise ValueError('An unexpected error occurred')"}
{"task_id": "BigCodeBench/139", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or not all(df.columns.isnumeric()):\n        raise ValueError(\"Input must be a non-empty DataFrame with numeric columns.\")\n    \n    for col in df.columns:\n        plt.hist(df[col], bins=10, edgecolor='black')\n        plt.title(col)\n        plt.xlabel('Value')\n        plt.ylabel('Frequency')\n        plt.show()", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or not all(df.columns.isnumeric()):\n        raise ValueError(\"Input must be a non-empty DataFrame with numeric columns.\")\n    \n    for col in df.columns:\n        plt.hist(df[col], bins=10, edgecolor='black')\n        plt.title(col)\n        plt.xlabel('Value')\n        plt.ylabel('Frequency')\n        plt.show()\n```"}
{"task_id": "BigCodeBench/147", "solution": "import socket\nfrom ipaddress import IPv4Network\nfrom threading import Thread\ndef task_func(ip_range, port):\n    threads = []\n    for ip in ip_range:\n        thread = Thread(target=check_port_status, args=(ip, port))\n        thread.start()\n        threads.append(thread)\n    for thread in threads:\n        thread.join()\n    return {ip: port_status for ip, port_status in port_status.items() if port_status}\ndef check_port_status(ip, port):\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    sock.settimeout(1)\n    sock.connect((ip, port))\n    sock.shutdown(2)\n    sock.close()\n    return True", "raw_solution": "import socket\nfrom ipaddress import IPv4Network\nfrom threading import Thread\n\ndef task_func(ip_range, port):\n    threads = []\n    for ip in ip_range:\n        thread = Thread(target=check_port_status, args=(ip, port))\n        thread.start()\n        threads.append(thread)\n    for thread in threads:\n        thread.join()\n    return {ip: port_status for ip, port_status in port_status.items() if port_status}\n\ndef check_port_status(ip, port):\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    sock.settimeout(1)\n    sock.connect((ip, port))\n    sock.shutdown(2)\n    sock.close()\n    return True"}
{"task_id": "BigCodeBench/161", "solution": "import re\nimport pandas as pd\nfrom datetime import datetime\ndef task_func(log_file):\n    with open(log_file, 'r') as f:\n        log_data = f.read()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()", "raw_solution": "import re\nimport pandas as pd\nfrom datetime import datetime\n\ndef task_func(log_file):\n    with open(log_file, 'r') as f:\n        log_data = f.read()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+', ' ', log_data).strip()\n    log_data = re.sub(r'\\s+',"}
{"task_id": "BigCodeBench/162", "solution": "import re\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(text, rwidth=0.8):\n    # Remove punctuation and convert text to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n    \n    # Split text into words\n    words = text.split()\n    \n    # Count word lengths\n    word_lengths = [len(word) for word in words]\n    \n    # Create histogram subplot\n    plt.hist(word_lengths, rwidth)\n    \n    # Show plot\n    plt.show()\n    \n    return plt.gca()", "raw_solution": "import re\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(text, rwidth=0.8):\n    # Remove punctuation and convert text to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text).lower()\n    \n    # Split text into words\n    words = text.split()\n    \n    # Count word lengths\n    word_lengths = [len(word) for word in words]\n    \n    # Create histogram subplot\n    plt.hist(word_lengths, rwidth)\n    \n    # Show plot\n    plt.show()\n    \n    return plt.gca()\n\n# Test the function\ntask_func(\"This is a test text with some words.\")\n```"}
{"task_id": "BigCodeBench/177", "solution": "import re\nimport nltk\nfrom string import punctuation\ndef task_func(df):\n    if not df['Title'].empty and not df['Content'].empty:\n        titles = df['Title'].str.lower().str.strip().str.cat(' ')\n        content = df['Content'].str.lower().str.strip().str.cat(' ')\n        words = nltk.word_tokenize(titles + content)\n        word_freq = nltk.FreqDist(words)\n        return dict(word_freq)\n    else:\n        raise ValueError(\"DataFrame is empty or does not contain the necessary columns 'Title' and 'Content'.\")", "raw_solution": "import re\nimport nltk\nfrom string import punctuation\n\ndef task_func(df):\n    if not df['Title'].empty and not df['Content'].empty:\n        titles = df['Title'].str.lower().str.strip().str.cat(' ')\n        content = df['Content'].str.lower().str.strip().str.cat(' ')\n        words = nltk.word_tokenize(titles + content)\n        word_freq = nltk.FreqDist(words)\n        return dict(word_freq)\n    else:\n        raise ValueError(\"DataFrame is empty or does not contain the necessary columns 'Title' and 'Content'.\")\n```"}
{"task_id": "BigCodeBench/184", "solution": "import pandas as pd\nimport re\nfrom sklearn.feature_extraction.text import CountVectorizer\ndef task_func(dataframe, text_column):\n    # Remove stopwords and numbers\n    dataframe[text_column] = dataframe[text_column].apply(lambda x: re.sub(r'\\d+', '', x))\n    # Vectorize text\n    vectorizer = CountVectorizer()\n    vectorized_data = vectorizer.fit_transform(dataframe[text_column])\n    return dataframe, vectorized_data", "raw_solution": "import pandas as pd\nimport re\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ndef task_func(dataframe, text_column):\n    # Remove stopwords and numbers\n    dataframe[text_column] = dataframe[text_column].apply(lambda x: re.sub(r'\\d+', '', x))\n    # Vectorize text\n    vectorizer = CountVectorizer()\n    vectorized_data = vectorizer.fit_transform(dataframe[text_column])\n    return dataframe, vectorized_data"}
{"task_id": "BigCodeBench/187", "solution": "import numpy as np\nimport geopandas as gpd\nfrom shapely.geometry import Point\ndef task_func(dic={'Lon': (-180, 180), 'Lat': (-90, 90)}, cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney']):\n    gdf = gpd.GeoDataFrame({'City': cities, 'Coordinates': [Point(lon, lat) for lon, lat in dic.items()]})\n    return gdf", "raw_solution": "import numpy as np\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\ndef task_func(dic={'Lon': (-180, 180), 'Lat': (-90, 90)}, cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney']):\n    gdf = gpd.GeoDataFrame({'City': cities, 'Coordinates': [Point(lon, lat) for lon, lat in dic.items()]})\n    return gdf\n```"}
{"task_id": "BigCodeBench/199", "solution": "import pandas as pd\nimport pytz\nfrom datetime import datetime\nfrom random import randint, seed as set_seed\ndef task_func(\n    utc_datetime,\n    cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney'],\n    weather_conditions=['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy'],\n    timezones={\n        'New York': 'America/New_York',\n        'London': 'Europe/London',\n        'Beijing': 'Asia/Shanghai',\n        'Tokyo': 'Asia/Tokyo',\n        'Sydney': 'Australia/Sydney'\n    },\n    seed=42\n):\n    # Validate utc_datetime\n    if not isinstance(utc_datetime, datetime):\n        raise ValueError(\"utc_datetime must be a datetime object\")\n    if not all(isinstance(city, str) for city in cities):\n        raise ValueError(\"cities must be a list of strings\")\n    if not all(isinstance(condition, str) for condition in weather_conditions):\n        raise ValueError(\"weather_conditions must be a list of strings\")\n    if not all(isinstance(timezone, str) for timezone in timezones):\n        raise ValueError(\"timezones must be a list of strings\")\n\n    # Generate random seed\n    set_seed(seed)\n\n    # Generate weather report\n    weather_report = pd.DataFrame({\n        'City': cities,\n        'Local Time': utc_datetime.astimezone(pytz.timezone(timezones[0])).strftime('%Y-%m-%d %H:%M:%S %Z%z'),\n        'Weather Condition': random.choice(weather_conditions)\n    })\n\n    return weather_report", "raw_solution": "import pandas as pd\nimport pytz\nfrom datetime import datetime\nfrom random import randint, seed as set_seed\n\ndef task_func(\n    utc_datetime,\n    cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney'],\n    weather_conditions=['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy'],\n    timezones={\n        'New York': 'America/New_York',\n        'London': 'Europe/London',\n        'Beijing': 'Asia/Shanghai',\n        'Tokyo': 'Asia/Tokyo',\n        'Sydney': 'Australia/Sydney'\n    },\n    seed=42\n):\n    # Validate utc_datetime\n    if not isinstance(utc_datetime, datetime):\n        raise ValueError(\"utc_datetime must be a datetime object\")\n    if not all(isinstance(city, str) for city in cities):\n        raise ValueError(\"cities must be a list of strings\")\n    if not all(isinstance(condition, str) for condition in weather_conditions):\n        raise ValueError(\"weather_conditions must be a list of strings\")\n    if not all(isinstance(timezone, str) for timezone in timezones):\n        raise ValueError(\"timezones must be a list of strings\")\n\n    # Generate random seed\n    set_seed(seed)\n\n    # Generate weather report\n    weather_report = pd.DataFrame({\n        'City': cities,\n        'Local Time': utc_datetime.astimezone(pytz.timezone(timezones[0])).strftime('%Y-%m-%d %H:%M:%S %Z%z'),\n        'Weather Condition': random.choice(weather_conditions)\n    })\n\n    return weather_report"}
{"task_id": "BigCodeBench/208", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(elements, seed=0):\n    np.random.seed(seed)\n    random_walk = np.random.choice([-1, 1], size=elements)\n    return {'count': len(random_walk), 'mean': np.mean(random_walk), 'std': np.std(random_walk), 'min': np.min(random_walk), '5th': np.percentile(random_walk, 5), '25th': np.percentile(random_walk, 25), 'median': np.median(random_walk), '75th': np.percentile(random_walk, 75), '95th': np.percentile(random_walk, 95), 'max': np.max(random_walk)}", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(elements, seed=0):\n    np.random.seed(seed)\n    random_walk = np.random.choice([-1, 1], size=elements)\n    return {'count': len(random_walk), 'mean': np.mean(random_walk), 'std': np.std(random_walk), 'min': np.min(random_walk), '5th': np.percentile(random_walk, 5), '25th': np.percentile(random_walk, 25), 'median': np.median(random_walk), '75th': np.percentile(random_walk, 75), '95th': np.percentile(random_walk, 95), 'max': np.max(random_walk)}\n```"}
{"task_id": "BigCodeBench/211", "solution": "import requests\nimport os\nimport zipfile\ndef task_func(url, destination_directory, headers=None):\n    response = requests.get(url, headers=headers)\n    with zipfile.ZipFile(destination_directory, 'w') as zip_file:\n        zip_file.write(response.raw.file)\n    return list(os.listdir(destination_directory))", "raw_solution": "import requests\nimport os\nimport zipfile\n\ndef task_func(url, destination_directory, headers=None):\n    response = requests.get(url, headers=headers)\n    with zipfile.ZipFile(destination_directory, 'w') as zip_file:\n        zip_file.write(response.raw.file)\n    return list(os.listdir(destination_directory))\n```"}
{"task_id": "BigCodeBench/214", "solution": "import random\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\ndef task_func(seed=42, image_size=(100, 100, 3), range_low=0, range_high=255):\n    random.seed(seed)\n    image = np.random.randint(range_low, range_high, size=image_size)\n    plt.imshow(image)\n    plt.show()\n    return image", "raw_solution": "import random\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\ndef task_func(seed=42, image_size=(100, 100, 3), range_low=0, range_high=255):\n    random.seed(seed)\n    image = np.random.randint(range_low, range_high, size=image_size)\n    plt.imshow(image)\n    plt.show()\n    return image\n```"}
{"task_id": "BigCodeBench/227", "solution": "import numpy as np\nimport os\nimport soundfile as sf\nimport librosa\nimport matplotlib.pyplot as plt\ndef task_func(L, M, N, audio_file):\n    try:\n        data, sr = librosa.load(audio_file, sr=None)\n        SPL = 20 * np.log10(np.sqrt(np.mean(data**2)))\n        normalized_matrix = np.array([SPL] * M * N)\n        plt.figure()\n        plt.spectrogram(normalized_matrix, sr, NFFT=256, Fs=sr)\n        plt.show()\n    except FileNotFoundError:\n        print(\"Error: The specified audio file does not exist.\")", "raw_solution": "import numpy as np\nimport os\nimport soundfile as sf\nimport librosa\nimport matplotlib.pyplot as plt\n\ndef task_func(L, M, N, audio_file):\n    try:\n        data, sr = librosa.load(audio_file, sr=None)\n        SPL = 20 * np.log10(np.sqrt(np.mean(data**2)))\n        normalized_matrix = np.array([SPL] * M * N)\n        plt.figure()\n        plt.spectrogram(normalized_matrix, sr, NFFT=256, Fs=sr)\n        plt.show()\n    except FileNotFoundError:\n        print(\"Error: The specified audio file does not exist.\")"}
{"task_id": "BigCodeBench/239", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\ndef task_func(original):\n    # Extract numeric values\n    numeric_values = [value for value, _ in original]\n    \n    # Compute basic statistics\n    mean = np.mean(numeric_values)\n    std_dev = np.std(numeric_values)\n    min_val = np.min(numeric_values)\n    max_val = np.max(numeric_values)\n    \n    # Generate a histogram with an overlaid probability density function (PDF)\n    fig, ax = plt.subplots()\n    ax.hist(numeric_values, bins='auto', density=True, alpha=0.6)\n    ax.set(xlim=(min_val, max_val), xticks=np.arange(0, max_val, 10))\n    ax.set(ylim=(0, 1))\n    return np.array(numeric_values), dict(mean=mean, std_dev=std_dev, min_val=min_val, max_val=max_val), ax", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\ndef task_func(original):\n    # Extract numeric values\n    numeric_values = [value for value, _ in original]\n    \n    # Compute basic statistics\n    mean = np.mean(numeric_values)\n    std_dev = np.std(numeric_values)\n    min_val = np.min(numeric_values)\n    max_val = np.max(numeric_values)\n    \n    # Generate a histogram with an overlaid probability density function (PDF)\n    fig, ax = plt.subplots()\n    ax.hist(numeric_values, bins='auto', density=True, alpha=0.6)\n    ax.set(xlim=(min_val, max_val), xticks=np.arange(0, max_val, 10))\n    ax.set(ylim=(0, 1))\n    return np.array(numeric_values), dict(mean=mean, std_dev=std_dev, min_val=min_val, max_val=max_val), ax\n```"}
{"task_id": "BigCodeBench/241", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\ndef task_func(original):\n    # Create a numeric array from the \"original\" list\n    original_array = np.array(original)\n    \n    # Normalize the array\n    normalized_array = preprocessing.normalize(original_array)\n    \n    # Plot the original and normalized arrays\n    plt.figure()\n    plt.plot(original_array, label='Original Data')\n    plt.plot(normalized_array, label='Normalized Data')\n    plt.title('Original vs. Normalized Data')\n    plt.legend()\n    plt.show()\n    \n    return original_array, normalized_array", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\n\ndef task_func(original):\n    # Create a numeric array from the \"original\" list\n    original_array = np.array(original)\n    \n    # Normalize the array\n    normalized_array = preprocessing.normalize(original_array)\n    \n    # Plot the original and normalized arrays\n    plt.figure()\n    plt.plot(original_array, label='Original Data')\n    plt.plot(normalized_array, label='Normalized Data')\n    plt.title('Original vs. Normalized Data')\n    plt.legend()\n    plt.show()\n    \n    return original_array, normalized_array"}
{"task_id": "BigCodeBench/267", "solution": "import numpy as np\nfrom scipy import fftpack\nimport matplotlib.pyplot as plt\ndef task_func(data, sample_rate=8000):\n    # Add a new key \"a\" with the value 1 to the dictionary\n    data['a'] = 1\n\n    # Generate a signal based on the values in \"data\"\n    signal = np.sin(2 * np.pi * data['a'] * sample_rate)\n\n    # Run a Fast Fourier Transform (FFT) on the signal\n    fft_result = fftpack.fft(signal)\n\n    # Plot and return the FFT of the signal\n    return fft_result, plt.plot(fft_result)", "raw_solution": "import numpy as np\nfrom scipy import fftpack\nimport matplotlib.pyplot as plt\n\ndef task_func(data, sample_rate=8000):\n    # Add a new key \"a\" with the value 1 to the dictionary\n    data['a'] = 1\n\n    # Generate a signal based on the values in \"data\"\n    signal = np.sin(2 * np.pi * data['a'] * sample_rate)\n\n    # Run a Fast Fourier Transform (FFT) on the signal\n    fft_result = fftpack.fft(signal)\n\n    # Plot and return the FFT of the signal\n    return fft_result, plt.plot(fft_result)\n```"}
{"task_id": "BigCodeBench/273", "solution": "import cgi\nimport http.server\nimport json\nSUCCESS_RESPONSE = {\n    'status': 'success',\n    'message': 'Data received successfully.'\n}\nERROR_RESPONSE = {\n    'status': 'error',\n    'message': 'Invalid data received.'\n}\ndef task_func():\n    request = cgi.FieldStorage()\n    data = request['data']\n    if not data:\n        return ERROR_RESPONSE\n    if 'data' not in data:\n        return ERROR_RESPONSE\n    return SUCCESS_RESPONSE", "raw_solution": "import cgi\nimport http.server\nimport json\nSUCCESS_RESPONSE = {\n    'status': 'success',\n    'message': 'Data received successfully.'\n}\nERROR_RESPONSE = {\n    'status': 'error',\n    'message': 'Invalid data received.'\n}\ndef task_func():\n    request = cgi.FieldStorage()\n    data = request['data']\n    if not data:\n        return ERROR_RESPONSE\n    if 'data' not in data:\n        return ERROR_RESPONSE\n    return SUCCESS_RESPONSE\n```"}
{"task_id": "BigCodeBench/274", "solution": "import cgi\nimport http.server\nimport smtplib\nfrom email.mime.text import MIMEText\nimport json\ndef task_func(smtp_server, smtp_port, smtp_username, smtp_password):\n    def process_email(email_data):\n        try:\n            email = json.loads(email_data)\n            return email\n        except json.JSONDecodeError:\n            raise ValueError(\"Invalid JSON data\")\n        except ValueError:\n            raise ValueError(\"Missing required keys: subject, message, to\")\n        except smtplib.SMTPAuthenticationError:\n            raise ValueError(\"Authentication issue with SMTP server\")\n    return process_email", "raw_solution": "import cgi\nimport http.server\nimport smtplib\nfrom email.mime.text import MIMEText\nimport json\ndef task_func(smtp_server, smtp_port, smtp_username, smtp_password):\n    def process_email(email_data):\n        try:\n            email = json.loads(email_data)\n            return email\n        except json.JSONDecodeError:\n            raise ValueError(\"Invalid JSON data\")\n        except ValueError:\n            raise ValueError(\"Missing required keys: subject, message, to\")\n        except smtplib.SMTPAuthenticationError:\n            raise ValueError(\"Authentication issue with SMTP server\")\n    return process_email\n```"}
{"task_id": "BigCodeBench/287", "solution": "from collections import Counter\nimport os\nimport json\ndef task_func(filename, directory):\n    total_words = 0\n    for filename in os.listdir(directory):\n        if filename.endswith(\".txt\"):\n            with open(os.path.join(directory, filename), \"r\") as f:\n                total_words += len(Counter(f.read().split()))\n    return total_words", "raw_solution": "from collections import Counter\nimport os\nimport json\n\ndef task_func(filename, directory):\n    total_words = 0\n    for filename in os.listdir(directory):\n        if filename.endswith(\".txt\"):\n            with open(os.path.join(directory, filename), \"r\") as f:\n                total_words += len(Counter(f.read().split()))\n    return total_words\n\n# Test the function"}
{"task_id": "BigCodeBench/302", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(df, plot=False):\n    if not df.empty and all(df[COLUMNS].apply(pd.Series)):\n        corr_matrix = df[COLUMNS].corr()\n        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n        if plot:\n            plt.show()\n        return df, None\n    else:\n        raise ValueError(\"DataFrame input is empty or has invalid 'Value' column.\")", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(df, plot=False):\n    if not df.empty and all(df[COLUMNS].apply(pd.Series)):\n        corr_matrix = df[COLUMNS].corr()\n        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n        if plot:\n            plt.show()\n        return df, None\n    else:\n        raise ValueError(\"DataFrame input is empty or has invalid 'Value' column.\")\n```"}
{"task_id": "BigCodeBench/308", "solution": "import pandas as pd\nfrom statistics import mean\nimport random\nFIELDS = ['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History']\nSTUDENTS = ['Student_' + str(i) for i in range(1, 101)]\ndef task_func(additional_fields = []):\n    df = pd.DataFrame(columns=FIELDS)\n    for i in range(1, 101):\n        grades = [random.randint(0, 100) for _ in range(5)]\n        df.loc[i] = [STUDENTS[i-1], grades]\n    return df", "raw_solution": "import pandas as pd\nfrom statistics import mean\nimport random\n# Constants for generating the report data\nFIELDS = ['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History']\nSTUDENTS = ['Student_' + str(i) for i in range(1, 101)]\ndef task_func(additional_fields = []):\n    df = pd.DataFrame(columns=FIELDS)\n    for i in range(1, 101):\n        grades = [random.randint(0, 100) for _ in range(5)]\n        df.loc[i] = [STUDENTS[i-1], grades]\n    return df"}
{"task_id": "BigCodeBench/310", "solution": "import os\nimport csv\nimport random\nfrom statistics import mean\nCOLUMNS = ['Name', 'Age', 'Height', 'Weight']\nPEOPLE_COUNT = 100\ndef task_func(filename):\n    with open(filename, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(COLUMNS)\n        for i in range(PEOPLE_COUNT):\n            name = f'Name_{i}'\n            age = random.randint(18, 65)\n            height = random.uniform(1.5, 2.5)\n            weight = random.uniform(50, 150)\n            writer.writerow([name, age, height, weight])\n    return filename", "raw_solution": "import os\nimport csv\nimport random\nfrom statistics import mean\n\n# Constants\nCOLUMNS = ['Name', 'Age', 'Height', 'Weight']\nPEOPLE_COUNT = 100\n\ndef task_func(filename):\n    with open(filename, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(COLUMNS)\n        for i in range(PEOPLE_COUNT):\n            name = f'Name_{i}'\n            age = random.randint(18, 65)\n            height = random.uniform(1.5, 2.5)\n            weight = random.uniform(50, 150)\n            writer.writerow([name, age, height, weight])\n    return filename\n```"}
{"task_id": "BigCodeBench/313", "solution": "import re\nimport os\nimport shutil\nfrom datetime import datetime\ndef task_func(directory):\n    organized_files = []\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if re.search(r'\\[.*?\\]', file):\n                organized_files.append(os.path.join(root, file))\n    return organized_files, {'directories': organized_files}", "raw_solution": "import re\nimport os\nimport shutil\nfrom datetime import datetime\n\ndef task_func(directory):\n    organized_files = []\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if re.search(r'\\[.*?\\]', file):\n                organized_files.append(os.path.join(root, file))\n    return organized_files, {'directories': organized_files}\n\norganized_files, directories = task_func('path/to/directory')"}
{"task_id": "BigCodeBench/324", "solution": "import subprocess\nimport time\nimport threading\ndef task_func(file_list):\n    for file in file_list:\n        subprocess.run(['python', 'script.py', file])\nfile_list = ['file1.py', 'file2.py', 'file3.py']", "raw_solution": "import subprocess\nimport time\nimport threading\n\ndef task_func(file_list):\n    for file in file_list:\n        subprocess.run(['python', 'script.py', file])\n\n# Test the function\nfile_list = ['file1.py', 'file2.py', 'file3.py']\ntask_func(file_list)"}
{"task_id": "BigCodeBench/326", "solution": "import subprocess\nimport os\nimport sys\nimport glob\ndef task_func(directory_path):\n    file_list = glob.glob(os.path.join(directory_path, \"*.bat\"))\n    for file in file_list:\n        try:\n            subprocess.run(file, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            return (file, None)\n        except subprocess.CalledProcessError:\n            return (file, None)", "raw_solution": "import subprocess\nimport os\nimport sys\nimport glob\n\ndef task_func(directory_path):\n    file_list = glob.glob(os.path.join(directory_path, \"*.bat\"))\n    for file in file_list:\n        try:\n            subprocess.run(file, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            return (file, None)\n        except subprocess.CalledProcessError:\n            return (file, None)\n\ntask_func(\"path/to/directory\")"}
{"task_id": "BigCodeBench/341", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df, col):\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        raise ValueError(\"Input df must be DataFrame, not be empty\")\n    if col not in df.columns:\n        raise ValueError(\"Input df must contain the specified column\")\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n    sns.histplot(df[col], kde=True, ax=ax1)\n    sns.boxplot(df[col], ax=ax2)\n    plt.show()", "raw_solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df, col):\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        raise ValueError(\"Input df must be DataFrame, not be empty\")\n    if col not in df.columns:\n        raise ValueError(\"Input df must contain the specified column\")\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n    sns.histplot(df[col], kde=True, ax=ax1)\n    sns.boxplot(df[col], ax=ax2)\n    plt.show()\n```"}
{"task_id": "BigCodeBench/346", "solution": "import subprocess\nimport os\nimport sys\nimport time\ndef task_func(script_path, wait=True, *args):\n    try:\n        subprocess.run(['python', script_path], check=True, *args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        return 0\n    except subprocess.CalledProcessError as e:\n        return e.returncode", "raw_solution": "import subprocess\nimport os\nimport sys\nimport time\n\ndef task_func(script_path, wait=True, *args):\n    try:\n        subprocess.run(['python', script_path], check=True, *args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        return 0\n    except subprocess.CalledProcessError as e:\n        return e.returncode"}
{"task_id": "BigCodeBench/360", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\ndef task_func(file_location, sheet_name):\n    try:\n        df = pd.read_excel(file_location, sheet_name=sheet_name)\n        mean = df.mean()\n        std = df.std()\n        return {'mean': mean, 'std': std}\n    except FileNotFoundError:\n        raise ValueError('The specified file does not exist at the specified path.')\n    except ValueError:\n        raise ValueError('The specified sheet does not exist in the workbook.')", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\ndef task_func(file_location, sheet_name):\n    try:\n        df = pd.read_excel(file_location, sheet_name=sheet_name)\n        mean = df.mean()\n        std = df.std()\n        return {'mean': mean, 'std': std}\n    except FileNotFoundError:\n        raise ValueError('The specified file does not exist at the specified path.')\n    except ValueError:\n        raise ValueError('The specified sheet does not exist in the workbook.')"}
{"task_id": "BigCodeBench/367", "solution": "from datetime import datetime\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\ndef task_func(activities):\n    if not all(isinstance(activity, datetime) for activity in activities):\n        raise TypeError(\"Activities must be datetime objects\")\n    fig, ax = plt.subplots()\n    ax.bar(ax.get_xticks(), [activity.day for activity in activities], \n           color='blue', width=0.5)\n    ax.set_xlabel('Day of the Week')\n    ax.set_ylabel('Number of Activities')\n    ax.set_title('Weekly Activity')\n    return fig", "raw_solution": "from datetime import datetime\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\n\ndef task_func(activities):\n    if not all(isinstance(activity, datetime) for activity in activities):\n        raise TypeError(\"Activities must be datetime objects\")\n    fig, ax = plt.subplots()\n    ax.bar(ax.get_xticks(), [activity.day for activity in activities], \n           color='blue', width=0.5)\n    ax.set_xlabel('Day of the Week')\n    ax.set_ylabel('Number of Activities')\n    ax.set_title('Weekly Activity')\n    return fig\n```"}
{"task_id": "BigCodeBench/368", "solution": "import os\nimport shutil\nimport random\ndef task_func(src_dir: str, dest_dir: str, seed: int = 100) -> str:\n    # Generate a random file name\n    filename = f\"{random.randint(1, 1000000)}.txt\"\n    # Move the file to the destination directory\n    shutil.move(src_dir + filename, dest_dir)\n    return filename", "raw_solution": "import os\nimport shutil\nimport random\n\ndef task_func(src_dir: str, dest_dir: str, seed: int = 100) -> str:\n    # Generate a random file name\n    filename = f\"{random.randint(1, 1000000)}.txt\"\n    # Move the file to the destination directory\n    shutil.move(src_dir + filename, dest_dir)\n    return filename"}
{"task_id": "BigCodeBench/374", "solution": "import glob\nimport os\nfrom openpyxl import load_workbook\ndef task_func(directory_path='./xlsx_files/'):\n    count = 0\n    for file in glob.glob(os.path.join(directory_path, '*.xlsx')):\n        wb = load_workbook(file)\n        for sheet in wb.sheetnames:\n            count += len(wb[sheet].values)\n    return count", "raw_solution": "import glob\nimport os\nfrom openpyxl import load_workbook\n\ndef task_func(directory_path='./xlsx_files/'):\n    count = 0\n    for file in glob.glob(os.path.join(directory_path, '*.xlsx')):\n        wb = load_workbook(file)\n        for sheet in wb.sheetnames:\n            count += len(wb[sheet].values)\n    return count\n"}
{"task_id": "BigCodeBench/399", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport math\ndef task_func(frequency, sample_size=10000):\n    if frequency < 0:\n        raise ValueError(\"Frequency must be non-negative.\")\n    if sample_size <= 0:\n        raise ValueError(\"Sample size must be positive.\")\n\n    x = np.linspace(0, 2 * math.pi, sample_size)\n    y_sine = np.sin(x)\n    y_cosine = np.cos(x)\n\n    plt.figure()\n    plt.plot(x, y_sine, label=\"Sine wave\")\n    plt.plot(x, y_cosine, label=\"Cosine wave\")\n    plt.legend()\n    plt.show()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport math\n\ndef task_func(frequency, sample_size=10000):\n    if frequency < 0:\n        raise ValueError(\"Frequency must be non-negative.\")\n    if sample_size <= 0:\n        raise ValueError(\"Sample size must be positive.\")\n\n    x = np.linspace(0, 2 * math.pi, sample_size)\n    y_sine = np.sin(x)\n    y_cosine = np.cos(x)\n\n    plt.figure()\n    plt.plot(x, y_sine, label=\"Sine wave\")\n    plt.plot(x, y_cosine, label=\"Cosine wave\")\n    plt.legend()\n    plt.show()\n\n# Test the function\ntask_func(2)\n```"}
{"task_id": "BigCodeBench/401", "solution": "from flask import Flask\nimport os\nfrom flask_mail import Mail\ndef task_func(app_name):\n    app = Flask(app_name)\n    mail = Mail(app)\n    return (app, mail.config)", "raw_solution": "from flask import Flask\nimport os\nfrom flask_mail import Mail\n\ndef task_func(app_name):\n    app = Flask(app_name)\n    mail = Mail(app)\n    return (app, mail.config)\n```"}
{"task_id": "BigCodeBench/409", "solution": "import os\nimport pandas as pd\nimport numpy as np\ndef task_func(excel_file_path, file_name, column_name):\n    try:\n        df = pd.read_excel(excel_file_path, sheet_name=column_name)\n        mean = df[column_name].mean()\n        median = df[column_name].median()\n        std_dev = df[column_name].std()\n        return {'mean': mean, 'median': median, 'std_dev': std_dev}\n    except FileNotFoundError:\n        raise ValueError(\"The specified file does not exist at the specified path.\")\n    except ValueError:\n        raise ValueError(\"The specified column is not found in the Excel file.\")", "raw_solution": "import os\nimport pandas as pd\nimport numpy as np\n\ndef task_func(excel_file_path, file_name, column_name):\n    try:\n        df = pd.read_excel(excel_file_path, sheet_name=column_name)\n        mean = df[column_name].mean()\n        median = df[column_name].median()\n        std_dev = df[column_name].std()\n        return {'mean': mean, 'median': median, 'std_dev': std_dev}\n    except FileNotFoundError:\n        raise ValueError(\"The specified file does not exist at the specified path.\")\n    except ValueError:\n        raise ValueError(\"The specified column is not found in the Excel file.\")\n```"}
{"task_id": "BigCodeBench/417", "solution": "from sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import SGD\ndef task_func(X, Y):\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n    model = Sequential()\n    model.add(Dense(10, input_dim=2, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n    model.fit(X_train, Y_train, epochs=100, verbose=0)\n    return model", "raw_solution": "from sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import SGD\n\ndef task_func(X, Y):\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n    model = Sequential()\n    model.add(Dense(10, input_dim=2, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n    model.fit(X_train, Y_train, epochs=100, verbose=0)\n    return model\n```"}
{"task_id": "BigCodeBench/418", "solution": "from tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\ndef task_func(X, Y):\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n    model = keras.models.Sequential([\n        keras.layers.Dense(10, activation='sigmoid', input_shape=(X_train.shape[1],)),\n        keras.layers.Softmax()\n    ])\n    model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n    model.fit(X_train, Y_train, epochs=100, batch_size=32, validation_data=(X_test, Y_test))\n    y_pred = model.predict(X_test)\n    y_pred = y_pred > 0.5\n    roc_auc = auc(y_test, y_pred)\n    return model, roc_auc", "raw_solution": "from tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\n\ndef task_func(X, Y):\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n    model = keras.models.Sequential([\n        keras.layers.Dense(10, activation='sigmoid', input_shape=(X_train.shape[1],)),\n        keras.layers.Softmax()\n    ])\n    model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n    model.fit(X_train, Y_train, epochs=100, batch_size=32, validation_data=(X_test, Y_test))\n    y_pred = model.predict(X_test)\n    y_pred = y_pred > 0.5\n    roc_auc = auc(y_test, y_pred)\n    return model, roc_auc\n```"}
{"task_id": "BigCodeBench/424", "solution": "import cv2\nimport numpy as np\nimport os\nfrom sklearn.cluster import KMeans\ndef task_func(image_path='image.jpg', n_clusters=3, random_seed=42):\n    # Read the image\n    image = cv2.imread(image_path)\n    # Apply K-means clustering\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_seed)\n    kmeans.fit(image)\n    # Save the original and segmented images\n    original_image = image\n    segmented_image = kmeans.cluster_centers_\n    return original_image, segmented_image", "raw_solution": "import cv2\nimport numpy as np\nimport os\nfrom sklearn.cluster import KMeans\n\ndef task_func(image_path='image.jpg', n_clusters=3, random_seed=42):\n    # Read the image\n    image = cv2.imread(image_path)\n    # Apply K-means clustering\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_seed)\n    kmeans.fit(image)\n    # Save the original and segmented images\n    original_image = image\n    segmented_image = kmeans.cluster_centers_\n    return original_image, segmented_image"}
{"task_id": "BigCodeBench/443", "solution": "import numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\ndef task_func(\n    P: np.ndarray,\n    T: np.ndarray,\n    n_clusters: int = 3,\n    random_state: int = 0,\n    n_init: int = 10,\n) -> (np.ndarray, plt.Axes):\n    \"\"\"\n    Calculate the product of a matrix 'P' and a 3D tensor 'T', flatten the result, apply KMeans clustering to the flattened data, and visualize it.\n    \"\"\"\n    result = P @ T\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=n_init)\n    kmeans.fit(result)\n    cluster_result = kmeans.labels_\n    ax = plt.gca()\n    ax.set_title('KMeans Clustering Visualization')\n    return cluster_result, ax", "raw_solution": "import numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ndef task_func(\n    P: np.ndarray,\n    T: np.ndarray,\n    n_clusters: int = 3,\n    random_state: int = 0,\n    n_init: int = 10,\n) -> (np.ndarray, plt.Axes):\n    \"\"\"\n    Calculate the product of a matrix 'P' and a 3D tensor 'T', flatten the result, apply KMeans clustering to the flattened data, and visualize it.\n    \"\"\"\n    result = P @ T\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=n_init)\n    kmeans.fit(result)\n    cluster_result = kmeans.labels_\n    ax = plt.gca()\n    ax.set_title('KMeans Clustering Visualization')\n    return cluster_result, ax"}
{"task_id": "BigCodeBench/445", "solution": "import numpy as np\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\nimport matplotlib.pyplot as plt\ndef task_func(points, seed=0):\n    # Create a Voronoi diagram for the given points\n    vor = Voronoi(points)\n    \n    # Plot the Voronoi diagram\n    ax = plt.figure().add_subplot(111)\n    voronoi_plot_2d(vor, ax=ax, show_labels=False, seed=seed)\n    \n    return (vor, ax)", "raw_solution": "import numpy as np\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\nimport matplotlib.pyplot as plt\n\ndef task_func(points, seed=0):\n    # Create a Voronoi diagram for the given points\n    vor = Voronoi(points)\n    \n    # Plot the Voronoi diagram\n    ax = plt.figure().add_subplot(111)\n    voronoi_plot_2d(vor, ax=ax, show_labels=False, seed=seed)\n    \n    return (vor, ax)"}
{"task_id": "BigCodeBench/454", "solution": "import os\nimport shutil\nimport glob\ndef task_func(src_dir, dest_dir, ext):\n    for file in glob.glob(os.path.join(src_dir, f'*.{ext}')):\n        if os.path.exists(os.path.join(dest_dir, file)):\n            continue\n        shutil.move(file, dest_dir)\n    return [os.path.join(dest_dir, file) for file in glob.glob(os.path.join(src_dir, f'*.{ext}'))]", "raw_solution": "import os\nimport shutil\nimport glob\n\ndef task_func(src_dir, dest_dir, ext):\n    for file in glob.glob(os.path.join(src_dir, f'*.{ext}')):\n        if os.path.exists(os.path.join(dest_dir, file)):\n            continue\n        shutil.move(file, dest_dir)\n    return [os.path.join(dest_dir, file) for file in glob.glob(os.path.join(src_dir, f'*.{ext}'))]\n```"}
{"task_id": "BigCodeBench/458", "solution": "import json\nimport re\nimport pandas as pd\ndef task_func(json_str):\n    data = json.loads(json_str)\n    normalized_data = {k: float(v) * 2 for k, v in data.items()}\n    return pd.DataFrame(normalized_data)", "raw_solution": "import json\nimport re\nimport pandas as pd\n\ndef task_func(json_str):\n    data = json.loads(json_str)\n    normalized_data = {k: float(v) * 2 for k, v in data.items()}\n    return pd.DataFrame(normalized_data)\n```"}
{"task_id": "BigCodeBench/461", "solution": "import subprocess\nimport psutil\nimport time\nimport os\ndef task_func(script_path: str, timeout=10) -> dict:\n    # Check if the script path exists\n    if not os.path.exists(script_path):\n        return {\"CPU Usage\": 0, \"Memory Usage\": 0}\n\n    # Execute the script in a subprocess\n    process = subprocess.Popen([script_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n    # Monitor the script's process for CPU and memory usage\n    while True:\n        cpu_usage, memory_usage = psutil.Process(process.pid).cpu_percent(interval=1), psutil.Process(process.pid).memory_info().rss\n        time.sleep(1)\n\n        # Aggregate the metrics until the script completes or the timeout is reached\n        if process.poll() is not None:\n            break\n\n    # Return the accumulated metrics as a dictionary\n    return {\"CPU Usage\": cpu_usage, \"Memory Usage\": memory_usage}", "raw_solution": "import subprocess\nimport psutil\nimport time\nimport os\n\ndef task_func(script_path: str, timeout=10) -> dict:\n    # Check if the script path exists\n    if not os.path.exists(script_path):\n        return {\"CPU Usage\": 0, \"Memory Usage\": 0}\n\n    # Execute the script in a subprocess\n    process = subprocess.Popen([script_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n    # Monitor the script's process for CPU and memory usage\n    while True:\n        cpu_usage, memory_usage = psutil.Process(process.pid).cpu_percent(interval=1), psutil.Process(process.pid).memory_info().rss\n        time.sleep(1)\n\n        # Aggregate the metrics until the script completes or the timeout is reached\n        if process.poll() is not None:\n            break\n\n    # Return the accumulated metrics as a dictionary\n    return {\"CPU Usage\": cpu_usage, \"Memory Usage\": memory_usage}\n```"}
{"task_id": "BigCodeBench/477", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(N=100, CATEGORIES=[\"A\", \"B\", \"C\", \"D\", \"E\"], seed=42):\n    np.random.seed(seed)\n    df = pd.DataFrame(np.random.rand(N, 3), columns=[\"x\", \"y\", \"category\"])\n    df[\"category\"] = np.random.choice(CATEGORIES, size=N, replace=True)\n    return df, plt.gca()", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(N=100, CATEGORIES=[\"A\", \"B\", \"C\", \"D\", \"E\"], seed=42):\n    np.random.seed(seed)\n    df = pd.DataFrame(np.random.rand(N, 3), columns=[\"x\", \"y\", \"category\"])\n    df[\"category\"] = np.random.choice(CATEGORIES, size=N, replace=True)\n    return df, plt.gca()\n\ndf, ax = task_func()\n```"}
{"task_id": "BigCodeBench/486", "solution": "import pandas as pd\nimport numpy as np\nfrom datetime import datetime\ndef task_func(start_time, end_time, step, trend, seed=42):\n    \"\"\"\n    Generate a time series from a given epoch start time to end time with a specified step and trend. The time series is plotted with timestamps on the x-axis ('Time') and values on the y-axis ('Value'). The values are generated from a normal distribution, and a linear trend is added based on the provided trend value.\n    \"\"\"\n    # Generate a time series with a specified step and trend\n    time_series = np.random.normal(start_time, step, end_time)\n    # Plot the time series with timestamps on the x-axis and values on the y-axis\n    ax = plt.gca()\n    ax.plot(time_series)\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Value')\n    ax.set_title('Time Series with Trend')\n    plt.show()\n    return ax", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom datetime import datetime\n\ndef task_func(start_time, end_time, step, trend, seed=42):\n    \"\"\"\n    Generate a time series from a given epoch start time to end time with a specified step and trend. The time series is plotted with timestamps on the x-axis ('Time') and values on the y-axis ('Value'). The values are generated from a normal distribution, and a linear trend is added based on the provided trend value.\n    \"\"\"\n    # Generate a time series with a specified step and trend\n    time_series = np.random.normal(start_time, step, end_time)\n    # Plot the time series with timestamps on the x-axis and values on the y-axis\n    ax = plt.gca()\n    ax.plot(time_series)\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Value')\n    ax.set_title('Time Series with Trend')\n    plt.show()\n    return ax"}
{"task_id": "BigCodeBench/492", "solution": "import pandas as pd\nfrom datetime import datetime\nimport random\ndef task_func(epoch_milliseconds, random_seed=0, products=[\"Product1\", \"Product2\", \"Product3\", \"Product4\", \"Product5\"]):\n    # Generate sales data for each day between the given epoch time to the current time\n    sales_data = []\n    for day in range(epoch_milliseconds // 1000 + 1):\n        date = datetime.fromtimestamp(epoch_milliseconds // 1000 + day)\n        sales_data.append({\n            \"Product\": random.choice(products),\n            \"Date\": date,\n            \"Sales\": random.randint(10, 50)\n        })\n    return pd.DataFrame(sales_data)", "raw_solution": "import pandas as pd\nfrom datetime import datetime\nimport random\n\ndef task_func(epoch_milliseconds, random_seed=0, products=[\"Product1\", \"Product2\", \"Product3\", \"Product4\", \"Product5\"]):\n    # Generate sales data for each day between the given epoch time to the current time\n    sales_data = []\n    for day in range(epoch_milliseconds // 1000 + 1):\n        date = datetime.fromtimestamp(epoch_milliseconds // 1000 + day)\n        sales_data.append({\n            \"Product\": random.choice(products),\n            \"Date\": date,\n            \"Sales\": random.randint(10, 50)\n        })\n    return pd.DataFrame(sales_data)"}
{"task_id": "BigCodeBench/501", "solution": "import xlwt\nimport os\nimport pandas as pd\ndef task_func(json_str, filename, sheet_name=\"sheet1\"):\n    try:\n        df = pd.read_json(json_str)\n        df.to_excel(filename, sheet_name=sheet_name, index=False)\n        return str(filename)\n    except ValueError:\n        raise ValueError(\"If `json_str` is not valid JSON.\")\n    except TypeError:\n        raise TypeError(\"If `json_str` is not a string, bytes, or bytearray.\")\n    except Exception:\n        raise Exception(\"For other general errors related to file writing.\")", "raw_solution": "import xlwt\nimport os\nimport pandas as pd\n\ndef task_func(json_str, filename, sheet_name=\"sheet1\"):\n    try:\n        df = pd.read_json(json_str)\n        df.to_excel(filename, sheet_name=sheet_name, index=False)\n        return str(filename)\n    except ValueError:\n        raise ValueError(\"If `json_str` is not valid JSON.\")\n    except TypeError:\n        raise TypeError(\"If `json_str` is not a string, bytes, or bytearray.\")\n    except Exception:\n        raise Exception(\"For other general errors related to file writing.\")\n```"}
{"task_id": "BigCodeBench/502", "solution": "from datetime import datetime, timedelta\nimport pandas as pd\nimport random\nimport seaborn as sns\ndef task_func(days_in_past=7, random_seed=0):\n    # Generate random activity durations\n    durations = [random.randint(0, 120) for _ in range(days_in_past)]\n    \n    # Create a sample DataFrame\n    df = pd.DataFrame({\n        'Date': [datetime.now() - timedelta(days=i) for i in range(days_in_past)],\n        'Activity': durations,\n        'Duration': durations\n    })\n    \n    # Plot the line plot\n    ax = sns.lineplot(data=df, x='Date', y='Duration', hue='Activity')\n    \n    return ax, df", "raw_solution": "from datetime import datetime, timedelta\nimport pandas as pd\nimport random\nimport seaborn as sns\n\ndef task_func(days_in_past=7, random_seed=0):\n    # Generate random activity durations\n    durations = [random.randint(0, 120) for _ in range(days_in_past)]\n    \n    # Create a sample DataFrame\n    df = pd.DataFrame({\n        'Date': [datetime.now() - timedelta(days=i) for i in range(days_in_past)],\n        'Activity': durations,\n        'Duration': durations\n    })\n    \n    # Plot the line plot\n    ax = sns.lineplot(data=df, x='Date', y='Duration', hue='Activity')\n    \n    return ax, df"}
{"task_id": "BigCodeBench/503", "solution": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime\ndef task_func(days_in_past=7, stock_names=[\"AAPL\", \"GOOGL\", \"MSFT\", \"AMZN\", \"FB\"], random_seed=0):\n    \"\"\"\n    Create a DataFrame of stock prices for the specified number of days in the past using random data.\n    \"\"\"\n    np.random.seed(random_seed)\n    stock_prices = np.random.rand(days_in_past, len(stock_names))\n    return pd.DataFrame(stock_prices, columns=stock_names)", "raw_solution": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime\n\ndef task_func(days_in_past=7, stock_names=[\"AAPL\", \"GOOGL\", \"MSFT\", \"AMZN\", \"FB\"], random_seed=0):\n    \"\"\"\n    Create a DataFrame of stock prices for the specified number of days in the past using random data.\n    \"\"\"\n    np.random.seed(random_seed)\n    stock_prices = np.random.rand(days_in_past, len(stock_names))\n    return pd.DataFrame(stock_prices, columns=stock_names)"}
{"task_id": "BigCodeBench/509", "solution": "import pandas as pd\nimport csv\nfrom difflib import ndiff\ndef task_func(file_path1, file_path2, delimiter=',', quotechar='\"'):\n    try:\n        df1 = pd.read_csv(file_path1, delimiter=delimiter, quotechar=quotechar)\n        df2 = pd.read_csv(file_path2, delimiter=delimiter, quotechar=quotechar)\n        diff = ndiff(df1, df2)\n        return pd.DataFrame(diff, columns=['Line Number', 'Status', 'Content'])\n    except FileNotFoundError:\n        raise FileNotFoundError(\"File not found\")\n    except ValueError:\n        raise ValueError(\"File is empty\")\n    except Exception:\n        raise Exception(\"Other IO related errors\")", "raw_solution": "import pandas as pd\nimport csv\nfrom difflib import ndiff\n\ndef task_func(file_path1, file_path2, delimiter=',', quotechar='\"'):\n    try:\n        df1 = pd.read_csv(file_path1, delimiter=delimiter, quotechar=quotechar)\n        df2 = pd.read_csv(file_path2, delimiter=delimiter, quotechar=quotechar)\n        diff = ndiff(df1, df2)\n        return pd.DataFrame(diff, columns=['Line Number', 'Status', 'Content'])\n    except FileNotFoundError:\n        raise FileNotFoundError(\"File not found\")\n    except ValueError:\n        raise ValueError(\"File is empty\")\n    except Exception:\n        raise Exception(\"Other IO related errors\")\n```"}
{"task_id": "BigCodeBench/511", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(column, data):\n    if len(data) == 0:\n        return (0, np.nan, np.nan, np.nan)\n    \n    sum_ = data[column].sum()\n    mean_ = data[column].mean()\n    min_ = data[column].min()\n    max_ = data[column].max()\n    \n    return (sum_, mean_, min_, max_)\ndata = pd.DataFrame({'Age': [25, 30, 28, 35, 40]})", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(column, data):\n    if len(data) == 0:\n        return (0, np.nan, np.nan, np.nan)\n    \n    sum_ = data[column].sum()\n    mean_ = data[column].mean()\n    min_ = data[column].min()\n    max_ = data[column].max()\n    \n    return (sum_, mean_, min_, max_)\n\n# Test the function\ndata = pd.DataFrame({'Age': [25, 30, 28, 35, 40]})\nresult = task_func('Age', data)"}
{"task_id": "BigCodeBench/513", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(column, data):\n    if column not in data.columns:\n        raise KeyError(\"Column is not valid\")\n    if any(data[column] < 0):\n        raise ValueError(\"Numeric values for steps, calories burned, and distance walked are negative\")\n    \n    sum_ = data[column].sum()\n    mean_ = data[column].mean()\n    min_ = data[column].min()\n    max_ = data[column].max()\n    \n    return (sum_, mean_, min_, max_)", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(column, data):\n    if column not in data.columns:\n        raise KeyError(\"Column is not valid\")\n    if any(data[column] < 0):\n        raise ValueError(\"Numeric values for steps, calories burned, and distance walked are negative\")\n    \n    sum_ = data[column].sum()\n    mean_ = data[column].mean()\n    min_ = data[column].min()\n    max_ = data[column].max()\n    \n    return (sum_, mean_, min_, max_)\n```"}
{"task_id": "BigCodeBench/526", "solution": "import json\nimport pandas as pd\nimport numpy as np\nfrom collections import defaultdict\ndef task_func(input_file=\"data.json\"):\n    df = pd.read_json(input_file)\n    mean = df.mean()\n    median = df.median()\n    return pd.DataFrame({\n        'mean': mean,\n        'median': median\n    })", "raw_solution": "import json\nimport pandas as pd\nimport numpy as np\nfrom collections import defaultdict\n\ndef task_func(input_file=\"data.json\"):\n    df = pd.read_json(input_file)\n    mean = df.mean()\n    median = df.median()\n    return pd.DataFrame({\n        'mean': mean,\n        'median': median\n    })\n\n# Test the function\ndf = task_func()"}
{"task_id": "BigCodeBench/528", "solution": "import csv\nfrom collections import Counter\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(file_path):\n    \"\"\"\n    Identifies duplicate rows from a CSV file using the csv library, convert duplicated rows into a pandas DataFrame, then plot using matplotlib.\n    \"\"\"\n    # Read the CSV file\n    df = pd.read_csv(file_path)\n    \n    # Convert duplicated rows into a pandas DataFrame\n    df = df.drop_duplicates()\n    \n    # Count the number of duplicate rows\n    duplicate_count = df.duplicated().sum()\n    \n    # Create a dictionary with duplicate rows as keys and their counts as values\n    duplicates = {row: df[df.duplicated().sum() == row].shape[0] for row in range(duplicate_count)}\n    \n    # Create a matplotlib Axes object with the bar chart of duplicate rows\n    fig, ax = plt.subplots()\n    ax.bar(duplicates.keys(), duplicates.values())\n    \n    # Return the dictionary and Axes objects\n    return duplicates, ax", "raw_solution": "import csv\nfrom collections import Counter\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(file_path):\n    \"\"\"\n    Identifies duplicate rows from a CSV file using the csv library, convert duplicated rows into a pandas DataFrame, then plot using matplotlib.\n    \"\"\"\n    # Read the CSV file\n    df = pd.read_csv(file_path)\n    \n    # Convert duplicated rows into a pandas DataFrame\n    df = df.drop_duplicates()\n    \n    # Count the number of duplicate rows\n    duplicate_count = df.duplicated().sum()\n    \n    # Create a dictionary with duplicate rows as keys and their counts as values\n    duplicates = {row: df[df.duplicated().sum() == row].shape[0] for row in range(duplicate_count)}\n    \n    # Create a matplotlib Axes object with the bar chart of duplicate rows\n    fig, ax = plt.subplots()\n    ax.bar(duplicates.keys(), duplicates.values())\n    \n    # Return the dictionary and Axes objects\n    return duplicates, ax"}
{"task_id": "BigCodeBench/530", "solution": "import pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df: pd.DataFrame) -> (Counter, plt.Axes):\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    age = df['age'].astype(int)\n    age = age.round().astype(int)\n    age = age.clip(0)\n    duplicates = df.duplicated(subset=['name', 'age'], keep='first')\n    age_distribution = age[duplicates].value_counts()\n    histogram = sns.histplot(age_distribution.index, y=age_distribution.values, bins=age_distribution.index[1] - .5)\n    return age_distribution, histogram", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df: pd.DataFrame) -> (Counter, plt.Axes):\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    age = df['age'].astype(int)\n    age = age.round().astype(int)\n    age = age.clip(0)\n    duplicates = df.duplicated(subset=['name', 'age'], keep='first')\n    age_distribution = age[duplicates].value_counts()\n    histogram = sns.histplot(age_distribution.index, y=age_distribution.values, bins=age_distribution.index[1] - .5)\n    return age_distribution, histogram\n```"}
{"task_id": "BigCodeBench/532", "solution": "import numpy as np\nfrom collections import Counter\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\ndef task_func(df, bins=4):\n    # Count duplicates in the 'value' column\n    duplicates = df['value'].value_counts()\n    \n    # Plot histogram\n    plt.hist(df['value'], bins=bins, color='green', alpha=0.6)\n    \n    # Overlay normal distribution curve\n    plt.plot(df['value'], norm.pdf(df['value'], df['value'].mean(), df['value'].std()), color='black', linewidth=2)\n    \n    # Title and labels\n    plt.title(\"Distribution\")\n    plt.xlabel(\"Value\")\n    plt.ylabel(\"Frequency\")\n    \n    # Return the result\n    return duplicates, plt.gca()\ndf = pd.DataFrame({'value': np.random.normal(0, 1, 1000)})", "raw_solution": "import numpy as np\nfrom collections import Counter\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\n\ndef task_func(df, bins=4):\n    # Count duplicates in the 'value' column\n    duplicates = df['value'].value_counts()\n    \n    # Plot histogram\n    plt.hist(df['value'], bins=bins, color='green', alpha=0.6)\n    \n    # Overlay normal distribution curve\n    plt.plot(df['value'], norm.pdf(df['value'], df['value'].mean(), df['value'].std()), color='black', linewidth=2)\n    \n    # Title and labels\n    plt.title(\"Distribution\")\n    plt.xlabel(\"Value\")\n    plt.ylabel(\"Frequency\")\n    \n    # Return the result\n    return duplicates, plt.gca()\n\n# Test the function\ndf = pd.DataFrame({'value': np.random.normal(0, 1, 1000)})\nduplicates, ax = task_func(df)\n```"}
{"task_id": "BigCodeBench/553", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(a, b):\n    df = pd.DataFrame(np.random.rand(5, 5), columns=COLUMNS)\n    df.plot.bar()\n    plt.show()", "raw_solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(a, b):\n    df = pd.DataFrame(np.random.rand(5, 5), columns=COLUMNS)\n    df.plot.bar()\n    plt.show()\n\ntask_func(np.random.rand(5, 5), COLUMNS)\n```"}
{"task_id": "BigCodeBench/560", "solution": "from datetime import datetime\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(data):\n    \"\"\"\n    This function plots a bar chart of monthly data values for a single year, with 'month' on the x-axis and 'value' on the y-axis.\n    The function should output with:\n    Axes object: A matplotlib.axes.Axes object representing the plot, with the title formatted as 'Monthly Data for yyyy', x label as 'Month', and y label as 'Value'.\n    \"\"\"\n    df = pd.DataFrame(data)\n    month = df['month']\n    value = df['value']\n    plt.bar(month, value)\n    plt.title('Monthly Data for yyyy')\n    plt.xlabel('Month')\n    plt.ylabel('Value')\n    plt.show()", "raw_solution": "from datetime import datetime\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(data):\n    \"\"\"\n    This function plots a bar chart of monthly data values for a single year, with 'month' on the x-axis and 'value' on the y-axis.\n    The function should output with:\n    Axes object: A matplotlib.axes.Axes object representing the plot, with the title formatted as 'Monthly Data for yyyy', x label as 'Month', and y label as 'Value'.\n    \"\"\"\n    df = pd.DataFrame(data)\n    month = df['month']\n    value = df['value']\n    plt.bar(month, value)\n    plt.title('Monthly Data for yyyy')\n    plt.xlabel('Month')\n    plt.ylabel('Value')\n    plt.show()\n```"}
{"task_id": "BigCodeBench/567", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(data):\n    \"\"\"\n    This function draws a histogram to visualize the frequency distribution of numeric values provided in a string format, with 'Value' on the x-axis, 'Frequency' on the y-axis and 'Histogram of Values' as the title.\n    Note that: The histogram uses bins calculated as `np.arange(data.min(), data.max()+2) - 0.5`.\n    The function should output with:\n    ax (matplotlib.axes._axes.Axes): The Axes object of the created histogram.\n    \"\"\"\n    ax = plt.hist(data, bins=np.arange(data.min(), data.max()+2) - 0.5, edgecolor='black')\n    return ax\ndata = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    \"\"\"\n    This function draws a histogram to visualize the frequency distribution of numeric values provided in a string format, with 'Value' on the x-axis, 'Frequency' on the y-axis and 'Histogram of Values' as the title.\n    Note that: The histogram uses bins calculated as `np.arange(data.min(), data.max()+2) - 0.5`.\n    The function should output with:\n    ax (matplotlib.axes._axes.Axes): The Axes object of the created histogram.\n    \"\"\"\n    ax = plt.hist(data, bins=np.arange(data.min(), data.max()+2) - 0.5, edgecolor='black')\n    return ax\n\n# Test the function\ndata = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nax = task_func(data)\nplt.show()\n```"}
{"task_id": "BigCodeBench/574", "solution": "from scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(array_length=100, noise_level=0.2):\n    x = np.linspace(0, 2 * np.pi, array_length)\n    y = np.sin(x) + noise_level * np.random.randn(array_length)\n    return x, y", "raw_solution": "from scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(array_length=100, noise_level=0.2):\n    x = np.linspace(0, 2 * np.pi, array_length)\n    y = np.sin(x) + noise_level * np.random.randn(array_length)\n    return x, y\n\nx, y = task_func()\nplt.plot(x, y)\nplt.show()"}
{"task_id": "BigCodeBench/579", "solution": "import unicodedata\nimport csv\nfrom collections import Counter\nimport matplotlib.pyplot as plt\ndef task_func(csv_file):\n    try:\n        with open(csv_file, 'r') as f:\n            reader = csv.reader(f)\n            text = [word for row in reader for word in row]\n            word_counts = Counter(text)\n            top_10_words = word_counts.most_common(10)\n            return top_10_words\n    except FileNotFoundError:\n        raise FileNotFoundError(\"CSV file not found at the specified path\")\n    except IOError:\n        raise IOError(\"Error in reading the file\")", "raw_solution": "import unicodedata\nimport csv\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef task_func(csv_file):\n    try:\n        with open(csv_file, 'r') as f:\n            reader = csv.reader(f)\n            text = [word for row in reader for word in row]\n            word_counts = Counter(text)\n            top_10_words = word_counts.most_common(10)\n            return top_10_words\n    except FileNotFoundError:\n        raise FileNotFoundError(\"CSV file not found at the specified path\")\n    except IOError:\n        raise IOError(\"Error in reading the file\")\n```"}
{"task_id": "BigCodeBench/582", "solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(size=1000):\n    x = np.random.normal(0, 1, size)\n    pdf = stats.norm.pdf(x)\n    hist, bins = np.histogram(x, bins=10)\n    plt.figure()\n    plt.plot(bins, hist, 'r')\n    plt.show()", "raw_solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(size=1000):\n    x = np.random.normal(0, 1, size)\n    pdf = stats.norm.pdf(x)\n    hist, bins = np.histogram(x, bins=10)\n    plt.figure()\n    plt.plot(bins, hist, 'r')\n    plt.show()\n\ntask_func()\n```"}
{"task_id": "BigCodeBench/583", "solution": "import rsa\nimport os\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Cipher import AES\nfrom base64 import b64encode, b64decode\ndef task_func():\n    # Generate RSA public and private key pair\n    public_key = rsa.generate_private_key(public_exponent=65537, key_size=2048)\n    private_key = public_key.public_key()\n\n    # Save private key in a file\n    filename = \"private_key_0x\" + b64encode(get_random_bytes(32)).decode()\n    private_key.save(filename)\n\n    # Encrypt private key with AES encryption\n    encrypted_private_key = private_key.encrypt(b\"test_password\", 16)\n\n    # Return public key, filename, and encryption details for testing\n    return rsa.PublicKey(**public_key), filename, encrypted_private_key", "raw_solution": "import rsa\nimport os\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Cipher import AES\nfrom base64 import b64encode, b64decode\n\ndef task_func():\n    # Generate RSA public and private key pair\n    public_key = rsa.generate_private_key(public_exponent=65537, key_size=2048)\n    private_key = public_key.public_key()\n\n    # Save private key in a file\n    filename = \"private_key_0x\" + b64encode(get_random_bytes(32)).decode()\n    private_key.save(filename)\n\n    # Encrypt private key with AES encryption\n    encrypted_private_key = private_key.encrypt(b\"test_password\", 16)\n\n    # Return public key, filename, and encryption details for testing\n    return rsa.PublicKey(**public_key), filename, encrypted_private_key\n\n# Call the function to test\nrsa_public_key, filename, encrypted_private_key = task_func()"}
{"task_id": "BigCodeBench/587", "solution": "import rsa\nimport os\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\nfrom cryptography.hazmat.primitives import padding\nfrom base64 import b64encode\ndef task_func(file_path):\n    # Generate RSA public and private keys\n    public_key = rsa.generate_private_key(\n        public_exponent=65537,\n        key_size=2048,\n        backend=default_backend()\n    )\n    private_key = public_key.private_bytes(\n        encoding=rsa.Encoding.PEM,\n        format=rsa.Encoding.PEM,\n        content=public_key.public_bytes(\n            encoding=rsa.Encoding.PEM,\n            format=rsa.Encoding.PEM\n        )\n    )\n\n    # Encrypt a file using AES encryption\n    with open(file_path, 'rb') as file:\n        encrypted_data = file.read()\n    cipher = Cipher(algorithms.AES(private_key.private_bytes(\n        encoding=rsa.Encoding.PEM,\n        format=rsa.Encoding.PEM,\n        content=private_key.public_bytes(\n            encoding=rsa.Encoding.PEM,\n            format=rsa.Encoding.PEM\n        )\n    ), modes.CBC(b64encode(encrypted_data).decode('utf-8'))), modes.CBC(b64encode(encrypted_data).decode('utf-8')))\n    encrypted_file = cipher.encrypt_file(file_path)\n\n    # Encrypt the AES key with the public RSA key\n    aes_key = b64encode(encrypted_data).decode('utf-8')\n    encrypted_aes_key = cipher.encrypt_file(os.path.join(os.getcwd(), 'aes_key'))\n\n    return rsa.PublicKey(public_key.public_bytes(\n        encoding=rsa.Encoding.PEM,\n        format=rsa.Encoding.PEM,\n        content=public_key.public_bytes(\n            encoding=rsa.Encoding.PEM,\n            format=rsa.Encoding.PEM\n        )\n    ), private_key=private_key), str(encrypted_file), str(encrypted_aes_key)", "raw_solution": "import rsa\nimport os\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\nfrom cryptography.hazmat.primitives import padding\nfrom base64 import b64encode\n\ndef task_func(file_path):\n    # Generate RSA public and private keys\n    public_key = rsa.generate_private_key(\n        public_exponent=65537,\n        key_size=2048,\n        backend=default_backend()\n    )\n    private_key = public_key.private_bytes(\n        encoding=rsa.Encoding.PEM,\n        format=rsa.Encoding.PEM,\n        content=public_key.public_bytes(\n            encoding=rsa.Encoding.PEM,\n            format=rsa.Encoding.PEM\n        )\n    )\n\n    # Encrypt a file using AES encryption\n    with open(file_path, 'rb') as file:\n        encrypted_data = file.read()\n    cipher = Cipher(algorithms.AES(private_key.private_bytes(\n        encoding=rsa.Encoding.PEM,\n        format=rsa.Encoding.PEM,\n        content=private_key.public_bytes(\n            encoding=rsa.Encoding.PEM,\n            format=rsa.Encoding.PEM\n        )\n    ), modes.CBC(b64encode(encrypted_data).decode('utf-8'))), modes.CBC(b64encode(encrypted_data).decode('utf-8')))\n    encrypted_file = cipher.encrypt_file(file_path)\n\n    # Encrypt the AES key with the public RSA key\n    aes_key = b64encode(encrypted_data).decode('utf-8')\n    encrypted_aes_key = cipher.encrypt_file(os.path.join(os.getcwd(), 'aes_key'))\n\n    return rsa.PublicKey(public_key.public_bytes(\n        encoding=rsa.Encoding.PEM,\n        format=rsa.Encoding.PEM,\n        content=public_key.public_bytes(\n            encoding=rsa.Encoding.PEM,\n            format=rsa.Encoding.PEM\n        )\n    ), private_key=private_key), str(encrypted_file), str(encrypted_aes_key)\n```"}
{"task_id": "BigCodeBench/590", "solution": "import urllib.request\nfrom pyquery import PyQuery as pq\nfrom datetime import datetime\nimport pandas as pd\ndef task_func(url):\n    try:\n        with urllib.request.urlopen(url) as response:\n            doc = pq(response.read())\n            text = doc('a').text()\n            href = doc('a').attr('href')\n            fetch_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n            return pd.DataFrame({'text': [text], 'href': [href], 'fetch_time': [fetch_time]})\n    except Exception as e:\n        raise ValueError(f\"Error occurred: {e}\")", "raw_solution": "import urllib.request\nfrom pyquery import PyQuery as pq\nfrom datetime import datetime\nimport pandas as pd\n\ndef task_func(url):\n    try:\n        with urllib.request.urlopen(url) as response:\n            doc = pq(response.read())\n            text = doc('a').text()\n            href = doc('a').attr('href')\n            fetch_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n            return pd.DataFrame({'text': [text], 'href': [href], 'fetch_time': [fetch_time]})\n    except Exception as e:\n        raise ValueError(f\"Error occurred: {e}\")"}
{"task_id": "BigCodeBench/592", "solution": "import csv\nimport os\nfrom datetime import datetime\nfrom random import randint\nSENSORS = ['Temperature', 'Humidity', 'Pressure']\nOUTPUT_DIR = './output'\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    for i in range(hours):\n        time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        with open(os.path.join(output_dir, f'{time}.csv'), 'w', newline='') as f:\n            writer = csv.writer(f)\n            writer.writerow(SENSORS)\n            writer.writerow([time, randint(20, 100), randint(20, 100)])\n        print(f'Successfully generated {hours} hours of data for {time}.csv')", "raw_solution": "import csv\nimport os\nfrom datetime import datetime\nfrom random import randint\n\n# Constants\nSENSORS = ['Temperature', 'Humidity', 'Pressure']\nOUTPUT_DIR = './output'\n\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    for i in range(hours):\n        time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        with open(os.path.join(output_dir, f'{time}.csv'), 'w', newline='') as f:\n            writer = csv.writer(f)\n            writer.writerow(SENSORS)\n            writer.writerow([time, randint(20, 100), randint(20, 100)])\n        print(f'Successfully generated {hours} hours of data for {time}.csv')"}
{"task_id": "BigCodeBench/593", "solution": "import csv\nimport os\nfrom datetime import datetime\nfrom random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(hours, output_dir='./output'):\n    # Generate traffic data for different vehicle types over a specified number of hours\n    data = generate_traffic_data(hours)\n    \n    # Save the data to a CSV file with coloumns 'Time', 'Car', 'Bus', 'Truck', and 'Bike'\n    save_data_to_csv(data, os.path.join(output_dir, 'traffic_data.csv'))\n    \n    # Plot the data in a line chart with 'Time' on x-axis and 'Vehicle Count' on y-axis\n    plot_traffic_data(data)\n    \n    return (os.path.join(output_dir, 'traffic_data.csv'), plt.gcf())", "raw_solution": "import csv\nimport os\nfrom datetime import datetime\nfrom random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Constants\nVEHICLE_TYPES = ['Car', 'Bus', 'Truck', 'Bike']\n\ndef task_func(hours, output_dir='./output'):\n    # Generate traffic data for different vehicle types over a specified number of hours\n    data = generate_traffic_data(hours)\n    \n    # Save the data to a CSV file with coloumns 'Time', 'Car', 'Bus', 'Truck', and 'Bike'\n    save_data_to_csv(data, os.path.join(output_dir, 'traffic_data.csv'))\n    \n    # Plot the data in a line chart with 'Time' on x-axis and 'Vehicle Count' on y-axis\n    plot_traffic_data(data)\n    \n    return (os.path.join(output_dir, 'traffic_data.csv'), plt.gcf())\n\ndef generate_traffic_data(hours):\n    # Generate traffic data for different vehicle types over a specified number of hours\n    return pd.DataFrame({\n        'Time': [datetime(2022, 1, 1, i) for i in range(hours)],\n        'Car': randint(1, 100) for _ in range(hours),\n        'Bus': randint(1, 100) for _ in range(hours),\n        'Truck': randint(1, 100) for _ in range(hours),\n        'Bike': randint(1, 100) for _ in range(hours)\n    })\n\ndef save_data_to_csv(data, filename):\n    # Save the data to a CSV file with coloumns 'Time', 'Car', 'Bus', 'Truck', and 'Bike'\n    with open(filename, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(['Time', 'Car', 'Bus', 'Truck', 'Bike'])\n        writer.writerows(data)\n\ndef plot_traffic_data(data):\n    # Plot the data in a line chart with 'Time' on x-axis and 'Vehicle Count' on y-axis\n    plt.plot(data['Time'], data['Vehicle Count'])\n    plt.xlabel('Time')\n    plt.ylabel('Vehicle Count')\n    plt.title('Traffic Data')\n    plt.show()"}
{"task_id": "BigCodeBench/594", "solution": "import csv\nimport os\nimport shutil\nfrom datetime import datetime\nfrom random import randint\nWEATHER_CONDITIONS = ['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy']\nOUTPUT_DIR = './output'\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    for i in range(hours):\n        time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        condition = randint(0, len(WEATHER_CONDITIONS) - 1)\n        filename = f'{output_dir}/weather_{time}_{condition}.csv'\n        with open(filename, 'w') as f:\n            writer = csv.writer(f)\n            writer.writerow([time, WEATHER_CONDITIONS[condition]])\n        print(f'Saved weather data for {time} to {filename}')\n    return filename", "raw_solution": "import csv\nimport os\nimport shutil\nfrom datetime import datetime\nfrom random import randint\n# Constants\nWEATHER_CONDITIONS = ['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy']\nOUTPUT_DIR = './output'\n\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    for i in range(hours):\n        time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        condition = randint(0, len(WEATHER_CONDITIONS) - 1)\n        filename = f'{output_dir}/weather_{time}_{condition}.csv'\n        with open(filename, 'w') as f:\n            writer = csv.writer(f)\n            writer.writerow([time, WEATHER_CONDITIONS[condition]])\n        print(f'Saved weather data for {time} to {filename}')\n    return filename\n```"}
{"task_id": "BigCodeBench/618", "solution": "from random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\ndef task_func(goals, penalties):\n    df = pd.DataFrame({\n        'Team': TEAMS,\n        'Goals': goals,\n        'Penalty Cost': penalties\n    })\n    return df", "raw_solution": "from random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\n# Constants\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000  # in dollars\n\ndef task_func(goals, penalties):\n    df = pd.DataFrame({\n        'Team': TEAMS,\n        'Goals': goals,\n        'Penalty Cost': penalties\n    })\n    return df\n\ndef visualize_results(df):\n    sns.set_theme(style=\"whitegrid\")\n    ax1 = sns.barplot(x=\"Team\", y=\"Goals\", data=df)\n    ax2 = sns.barplot(x=\"Team\", y=\"Penalty Cost\", data=df)\n    plt.show()\n\n# Test the function\ndf = task_func(randint(1, 100), randint(1, 100))\nvisualize_results(df)\n```"}
{"task_id": "BigCodeBench/636", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\ndef task_func(rows):\n    df = pd.DataFrame(np.random.randint(0, 10, size=(rows, 6)), columns=COLUMNS)\n    return df, plt.gca()", "raw_solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\ndef task_func(rows):\n    df = pd.DataFrame(np.random.randint(0, 10, size=(rows, 6)), columns=COLUMNS)\n    return df, plt.gca()\n\n# Test the function\ndf, ax = task_func(10)\n```"}
{"task_id": "BigCodeBench/637", "solution": "from random import sample\nfrom typing import Tuple\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\ndef task_func(num_students):\n    # Generate a random group of students\n    students = sample(range(1, 101), num_students)\n    \n    # Calculate the average grade in each course\n    grades = [np.mean([np.random.randint(60, 100) for _ in range(num_students)]) for _ in range(num_students)]\n    \n    # Calculate the number of students with a passing grade\n    passing_students = sum([1 for _ in range(num_students) if grades[_] >= 60])\n    \n    # Create a DataFrame with the grades and passing students\n    df = pd.DataFrame({'Grade': grades, 'Passing': [1 if x >= 60 else 0 for x in grades]})\n    \n    # Create a bar plot with title 'Course-wise Average and Passing Grade Counts'\n    plt.bar(df['Grade'], df['Passing'])\n    plt.title('Course-wise Average and Passing Grade Counts')\n    \n    # Return the DataFrame and the Axes object\n    return df, plt.gca()", "raw_solution": "from random import sample\nfrom typing import Tuple\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\ndef task_func(num_students):\n    # Generate a random group of students\n    students = sample(range(1, 101), num_students)\n    \n    # Calculate the average grade in each course\n    grades = [np.mean([np.random.randint(60, 100) for _ in range(num_students)]) for _ in range(num_students)]\n    \n    # Calculate the number of students with a passing grade\n    passing_students = sum([1 for _ in range(num_students) if grades[_] >= 60])\n    \n    # Create a DataFrame with the grades and passing students\n    df = pd.DataFrame({'Grade': grades, 'Passing': [1 if x >= 60 else 0 for x in grades]})\n    \n    # Create a bar plot with title 'Course-wise Average and Passing Grade Counts'\n    plt.bar(df['Grade'], df['Passing'])\n    plt.title('Course-wise Average and Passing Grade Counts')\n    \n    # Return the DataFrame and the Axes object\n    return df, plt.gca()"}
{"task_id": "BigCodeBench/654", "solution": "import matplotlib.pyplot as plt\nimport scipy.optimize as optimize\nimport numpy as np\ndef task_func(array, target_value):\n    popt, _ = optimize.curve_fit(lambda x, t: np.exp(-t) * np.exp(-x), array[:, 0], array[:, 1], p0=[1, 1])\n    return tuple(popt), plt.gca()\narray = np.array([[1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5]])\ntarget_value = 1", "raw_solution": "import matplotlib.pyplot as plt\nimport scipy.optimize as optimize\nimport numpy as np\n\ndef task_func(array, target_value):\n    popt, _ = optimize.curve_fit(lambda x, t: np.exp(-t) * np.exp(-x), array[:, 0], array[:, 1], p0=[1, 1])\n    return tuple(popt), plt.gca()\n\n# Test the function\narray = np.array([[1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5]])\ntarget_value = 1\noptimized_params, _ = task_func(array, target_value)"}
{"task_id": "BigCodeBench/655", "solution": "import re\nimport nltk\nfrom sklearn.decomposition import NMF\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nALPHANUMERIC = re.compile('[\\W_]+')\nSTOPWORDS = nltk.corpus.stopwords.words('english')\ndef task_func(texts, num_topics):\n    # Preprocess the input texts\n    texts = [ALPHANUMERIC.sub('', text.lower()) for text in texts]\n    vectorizer = TfidfVectorizer(stop_words=STOPWORDS)\n    tfidf_matrix = vectorizer.fit_transform(texts)\n    # Apply NMF to extract the specified number of topics\n    nmf = NMF(n_components=num_topics, random_state=0)\n    topics = nmf.fit_transform(tfidf_matrix)\n    return topics", "raw_solution": "import re\nimport nltk\nfrom sklearn.decomposition import NMF\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n# Ensure nltk's stopwords are downloaded\nnltk.download('stopwords')\n# Constants\nALPHANUMERIC = re.compile('[\\W_]+')\nSTOPWORDS = nltk.corpus.stopwords.words('english')\ndef task_func(texts, num_topics):\n    # Preprocess the input texts\n    texts = [ALPHANUMERIC.sub('', text.lower()) for text in texts]\n    vectorizer = TfidfVectorizer(stop_words=STOPWORDS)\n    tfidf_matrix = vectorizer.fit_transform(texts)\n    # Apply NMF to extract the specified number of topics\n    nmf = NMF(n_components=num_topics, random_state=0)\n    topics = nmf.fit_transform(tfidf_matrix)\n    return topics"}
{"task_id": "BigCodeBench/657", "solution": "import re\nimport nltk\nfrom gensim.models import Word2Vec\nALPHANUMERIC = re.compile('[\\W_]+')\ndef task_func(texts, stopwords=None):\n    # Clean texts\n    texts = [ALPHANUMERIC.sub('', text.lower()) for text in texts]\n    # Train Word2Vec model\n    model = Word2Vec(texts, vector_size=100, window=5, min_count=1, workers=4)\n    return model", "raw_solution": "import re\nimport nltk\nfrom gensim.models import Word2Vec\n# Constants\nALPHANUMERIC = re.compile('[\\W_]+')\ndef task_func(texts, stopwords=None):\n    # Clean texts\n    texts = [ALPHANUMERIC.sub('', text.lower()) for text in texts]\n    # Train Word2Vec model\n    model = Word2Vec(texts, vector_size=100, window=5, min_count=1, workers=4)\n    return model\n```"}
{"task_id": "BigCodeBench/678", "solution": "import pandas as pd\nimport json\nimport os\nimport shutil\ndef task_func(path):\n    df = pd.DataFrame()\n    for filename in os.listdir(path):\n        with open(os.path.join(path, filename)) as f:\n            data = json.load(f)\n            df = df.append(data, ignore_index=True)\n    df['Source'] = filename\n    return df", "raw_solution": "import pandas as pd\nimport json\nimport os\nimport shutil\n\ndef task_func(path):\n    df = pd.DataFrame()\n    for filename in os.listdir(path):\n        with open(os.path.join(path, filename)) as f:\n            data = json.load(f)\n            df = df.append(data, ignore_index=True)\n    df['Source'] = filename\n    return df\n\n# Test the function\ndf = task_func('path/to/directory')"}
{"task_id": "BigCodeBench/720", "solution": "import os\nimport csv\nimport random\nfrom datetime import datetime\ndef task_func():\n    # Generate random data for temperature and humidity\n    temperature = random.randint(20, 30)\n    humidity = random.randint(40, 60)\n    \n    # Write data to CSV file\n    with open('task_func_data/Output.txt', 'a', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow([temperature, humidity])\n    \n    # Delete the CSV file after use\n    os.remove('task_func_data/Output.txt')\n    return 'task_func_data/Output.txt'", "raw_solution": "import os\nimport csv\nimport random\nfrom datetime import datetime\n\ndef task_func():\n    # Generate random data for temperature and humidity\n    temperature = random.randint(20, 30)\n    humidity = random.randint(40, 60)\n    \n    # Write data to CSV file\n    with open('task_func_data/Output.txt', 'a', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow([temperature, humidity])\n    \n    # Delete the CSV file after use\n    os.remove('task_func_data/Output.txt')\n    return 'task_func_data/Output.txt'\n```"}
{"task_id": "BigCodeBench/723", "solution": "import urllib.request\nfrom bs4 import BeautifulSoup\nimport csv\nimport os\nCSV_FILE_PATH = 'scraped_data.csv'\ndef task_func(url):\n    response = urllib.request.urlopen(url)\n    soup = BeautifulSoup(response, 'html.parser')\n    data = soup.find_all('div', class_='data')\n    with open(CSV_FILE_PATH, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Data'])\n        for item in data:\n            writer.writerow([item.text])", "raw_solution": "import urllib.request\nfrom bs4 import BeautifulSoup\nimport csv\nimport os\n\n# Constants\nCSV_FILE_PATH = 'scraped_data.csv'\n\ndef task_func(url):\n    response = urllib.request.urlopen(url)\n    soup = BeautifulSoup(response, 'html.parser')\n    data = soup.find_all('div', class_='data')\n    with open(CSV_FILE_PATH, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Data'])\n        for item in data:\n            writer.writerow([item.text])"}
{"task_id": "BigCodeBench/752", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\ndef task_func(data, target_column, test_size=0.2, random_state = 0) -> float:\n    \"\"\"\n    Train a linear regression model and return the model score of the test set.\n    The provided DataFrame is used as training data, where target_column is used as target in training the model.\n    Before training the provided data is split into a training and a test set using test_size and random_state parameters.\n    \"\"\"\n    X = data.drop(target_column, axis=1)\n    y = data[target_column]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    return model.score(X_test, y_test)", "raw_solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\n\ndef task_func(data, target_column, test_size=0.2, random_state = 0) -> float:\n    \"\"\"\n    Train a linear regression model and return the model score of the test set.\n    The provided DataFrame is used as training data, where target_column is used as target in training the model.\n    Before training the provided data is split into a training and a test set using test_size and random_state parameters.\n    \"\"\"\n    X = data.drop(target_column, axis=1)\n    y = data[target_column]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    return model.score(X_test, y_test)\n```"}
{"task_id": "BigCodeBench/760", "solution": "import pandas as pd\nimport numpy as np\nimport codecs\nimport re\nimport datetime\ndef task_func(start_year=1980, end_year=2000, email_domain='example.com',\n           latin_names=['Sopet\u00f3n', 'M\u00e9ndez', 'G\u00f3mez', 'P\u00e9rez', 'Mu\u00f1oz'],\n           other_names=['Smith', 'Johnson', 'Williams', 'Brown', 'Jones'], \n           rng_seed=None):\n    df = pd.DataFrame(columns=['ID', 'Name', 'Date of Birth', 'Email'])\n    for i in range(100):\n        name = other_names[np.random.randint(len(other_names))]\n        birth_date = datetime.datetime(rng_seed + i, rng_seed + i, rng_seed + i)\n        email = f\"{name}@{email_domain}\"\n        df = df.append({'ID': i, 'Name': name, 'Date of Birth': birth_date, 'Email': email}, ignore_index=True)\n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nimport codecs\nimport re\nimport datetime\ndef task_func(start_year=1980, end_year=2000, email_domain='example.com',\n           latin_names=['Sopet\u00f3n', 'M\u00e9ndez', 'G\u00f3mez', 'P\u00e9rez', 'Mu\u00f1oz'],\n           other_names=['Smith', 'Johnson', 'Williams', 'Brown', 'Jones'], \n           rng_seed=None):\n    df = pd.DataFrame(columns=['ID', 'Name', 'Date of Birth', 'Email'])\n    for i in range(100):\n        name = other_names[np.random.randint(len(other_names))]\n        birth_date = datetime.datetime(rng_seed + i, rng_seed + i, rng_seed + i)\n        email = f\"{name}@{email_domain}\"\n        df = df.append({'ID': i, 'Name': name, 'Date of Birth': birth_date, 'Email': email}, ignore_index=True)\n    return df"}
{"task_id": "BigCodeBench/763", "solution": "import numpy as np\nfrom collections import defaultdict\nimport json\nimport csv\ndef task_func(input_file, output_file):\n    with open(input_file, 'r') as f:\n        data = json.load(f)\n    \n    results = defaultdict(dict)\n    for item in data:\n        for key in item:\n            results[key]['mean'] = np.mean(item[key])\n            results[key]['median'] = np.median(item[key])\n    \n    with open(output_file, 'w') as f:\n        writer = csv.DictWriter(f, fieldnames=results[0].keys())\n        writer.writeheader()\n        writer.writerows(results)", "raw_solution": "import numpy as np\nfrom collections import defaultdict\nimport json\nimport csv\n\ndef task_func(input_file, output_file):\n    with open(input_file, 'r') as f:\n        data = json.load(f)\n    \n    results = defaultdict(dict)\n    for item in data:\n        for key in item:\n            results[key]['mean'] = np.mean(item[key])\n            results[key]['median'] = np.median(item[key])\n    \n    with open(output_file, 'w') as f:\n        writer = csv.DictWriter(f, fieldnames=results[0].keys())\n        writer.writeheader()\n        writer.writerows(results)"}
{"task_id": "BigCodeBench/765", "solution": "import os\nfrom pathlib import Path\nimport shutil\ndef task_func(kwargs, target_dir=\"non_none_files\"):\n    copied_files = []\n    for file_path in kwargs:\n        if os.path.exists(file_path) and os.path.getsize(file_path) > 0:\n            shutil.copy(file_path, target_dir)\n            copied_files.append(file_path)\n    return copied_files", "raw_solution": "import os\nfrom pathlib import Path\nimport shutil\n\ndef task_func(kwargs, target_dir=\"non_none_files\"):\n    copied_files = []\n    for file_path in kwargs:\n        if os.path.exists(file_path) and os.path.getsize(file_path) > 0:\n            shutil.copy(file_path, target_dir)\n            copied_files.append(file_path)\n    return copied_files"}
{"task_id": "BigCodeBench/771", "solution": "import re\nimport os\nfrom pathlib import Path\nimport csv\ndef task_func(directory: str, pattern: str = r'^(.*?)-\\d+\\.csv$'):\n    new_files = []\n    for filename in os.listdir(directory):\n        if re.match(pattern, filename):\n            new_filename = re.sub(pattern, r'\\1-\\1.csv', filename)\n            new_files.append(new_filename)\n    return new_files", "raw_solution": "import re\nimport os\nfrom pathlib import Path\nimport csv\n\ndef task_func(directory: str, pattern: str = r'^(.*?)-\\d+\\.csv$'):\n    new_files = []\n    for filename in os.listdir(directory):\n        if re.match(pattern, filename):\n            new_filename = re.sub(pattern, r'\\1-\\1.csv', filename)\n            new_files.append(new_filename)\n    return new_files"}
{"task_id": "BigCodeBench/777", "solution": "import re\nimport os\nimport zipfile\ndef task_func(directory, pattern=r'^(.*?)-\\d+\\.zip$'):\n    extracted_dirs = []\n    for filename in os.listdir(directory):\n        if re.match(pattern, filename):\n            extracted_dir = os.path.join(directory, filename)\n            extracted_dirs.append(extracted_dir)\n    return extracted_dirs", "raw_solution": "import re\nimport os\nimport zipfile\n\ndef task_func(directory, pattern=r'^(.*?)-\\d+\\.zip$'):\n    extracted_dirs = []\n    for filename in os.listdir(directory):\n        if re.match(pattern, filename):\n            extracted_dir = os.path.join(directory, filename)\n            extracted_dirs.append(extracted_dir)\n    return extracted_dirs\n```"}
{"task_id": "BigCodeBench/785", "solution": "import subprocess\nimport os\nimport glob\nARCHIVE_DIR = '/tmp/archive'\ndef task_func(pattern):\n    archive_file = os.path.join(ARCHIVE_DIR, pattern)\n    subprocess.run(['tar', '-czf', archive_file, pattern])\n    return archive_file", "raw_solution": "import subprocess\nimport os\nimport glob\n# Constants\nARCHIVE_DIR = '/tmp/archive'\ndef task_func(pattern):\n    archive_file = os.path.join(ARCHIVE_DIR, pattern)\n    subprocess.run(['tar', '-czf', archive_file, pattern])\n    return archive_file\n```"}
{"task_id": "BigCodeBench/800", "solution": "import csv\nimport os\nfrom collections import Counter\ndef task_func(goals, penalties, csv_file_path=CSV_FILE_PATH):\n    count = Counter()\n    with open(csv_file_path, 'r') as file:\n        reader = csv.reader(file)\n        for row in reader:\n            count.update(row[0])\n    return count", "raw_solution": "import csv\nimport os\nfrom collections import Counter\n\ndef create_test_csv(filename, content):\n    with open(filename, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerows(content)\n\ndef task_func(goals, penalties, csv_file_path=CSV_FILE_PATH):\n    count = Counter()\n    with open(csv_file_path, 'r') as file:\n        reader = csv.reader(file)\n        for row in reader:\n            count.update(row[0])\n    return count"}
{"task_id": "BigCodeBench/826", "solution": "import re\nimport os\nimport shutil\ndef task_func(source_dir, target_dir, file_pattern=r'\\b[A-Za-z0-9]+\\.(txt|doc|docx)\\b'):\n    moved_files_count = 0\n    for filename in os.listdir(source_dir):\n        if re.match(file_pattern, filename):\n            shutil.move(os.path.join(source_dir, filename), os.path.join(target_dir, filename))\n            moved_files_count += 1\n    return moved_files_count", "raw_solution": "import re\nimport os\nimport shutil\n\ndef task_func(source_dir, target_dir, file_pattern=r'\\b[A-Za-z0-9]+\\.(txt|doc|docx)\\b'):\n    moved_files_count = 0\n    for filename in os.listdir(source_dir):\n        if re.match(file_pattern, filename):\n            shutil.move(os.path.join(source_dir, filename), os.path.join(target_dir, filename))\n            moved_files_count += 1\n    return moved_files_count"}
{"task_id": "BigCodeBench/845", "solution": "import re\nimport numpy as np\nfrom collections import Counter\nfrom Levenshtein import ratio\ndef task_func(text1, text2):\n    # Clean the texts by removing non-alphanumeric characters except spaces and converting to lowercase\n    text1 = ALPHANUMERIC.sub('', text1).lower()\n    text2 = ALPHANUMERIC.sub('', text2).lower()\n\n    # Compute cosine similarity\n    cosine_similarity = np.dot(Counter(text1.split()), Counter(text2.split())) / (len(text1.split()) * len(text2.split()))\n\n    # Compute Levenshtein ratio\n    levenshtein_ratio = ratio(text1, text2)\n\n    return tuple((cosine_similarity, levenshtein_ratio))", "raw_solution": "import re\nimport numpy as np\nfrom collections import Counter\nfrom Levenshtein import ratio\n\ndef task_func(text1, text2):\n    # Clean the texts by removing non-alphanumeric characters except spaces and converting to lowercase\n    text1 = ALPHANUMERIC.sub('', text1).lower()\n    text2 = ALPHANUMERIC.sub('', text2).lower()\n\n    # Compute cosine similarity\n    cosine_similarity = np.dot(Counter(text1.split()), Counter(text2.split())) / (len(text1.split()) * len(text2.split()))\n\n    # Compute Levenshtein ratio\n    levenshtein_ratio = ratio(text1, text2)\n\n    return tuple((cosine_similarity, levenshtein_ratio))\n```"}
{"task_id": "BigCodeBench/854", "solution": "from functools import reduce\nfrom itertools import permutations\nimport math\ndef task_func(numbers):\n    if not isinstance(numbers, list) or not all(isinstance(x, int) for x in numbers):\n        raise TypeError(\"If numbers is not a list of integers.\")\n    if any(x < 0 for x in numbers):\n        raise ValueError(\"If input numbers are negative.\")\n    \n    fac = [math.factorial(x) for x in numbers]\n    perm = permutations(numbers)\n    return [sum(fac[perm[i]]) for i in range(len(numbers))]", "raw_solution": "from functools import reduce\nfrom itertools import permutations\nimport math\n\ndef task_func(numbers):\n    if not isinstance(numbers, list) or not all(isinstance(x, int) for x in numbers):\n        raise TypeError(\"If numbers is not a list of integers.\")\n    if any(x < 0 for x in numbers):\n        raise ValueError(\"If input numbers are negative.\")\n    \n    fac = [math.factorial(x) for x in numbers]\n    perm = permutations(numbers)\n    return [sum(fac[perm[i]]) for i in range(len(numbers))]\n```"}
{"task_id": "BigCodeBench/857", "solution": "import warnings\nimport os\nimport glob\nimport shutil\nimport time\ndef task_func(SOURCE_DIR, DEST_DIR, EXTENSIONS):\n    transferred_files = []\n    for file in glob.glob(os.path.join(SOURCE_DIR, '*.' + EXTENSIONS)):\n        try:\n            shutil.move(file, DEST_DIR)\n            transferred_files.append(file)\n        except Exception as e:\n            warnings.warn(f\"Failed to transfer {file} due to {e}\")\n    return transferred_files", "raw_solution": "import warnings\nimport os\nimport glob\nimport shutil\nimport time\n\ndef task_func(SOURCE_DIR, DEST_DIR, EXTENSIONS):\n    transferred_files = []\n    for file in glob.glob(os.path.join(SOURCE_DIR, '*.' + EXTENSIONS)):\n        try:\n            shutil.move(file, DEST_DIR)\n            transferred_files.append(file)\n        except Exception as e:\n            warnings.warn(f\"Failed to transfer {file} due to {e}\")\n    return transferred_files"}
{"task_id": "BigCodeBench/865", "solution": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import zscore\nfrom sklearn.preprocessing import MinMaxScaler\ndef task_func(data):\n    \"\"\"\n    Normalizes the counts using z-score normalization and the weights using min-max scaling.\n    Returns a pandas DataFrame with the items, normalized counts, and normalized weights.\n    \"\"\"\n    # Normalize counts\n    z_scores = zscore(data)\n    # Normalize weights\n    min_max_scaler = MinMaxScaler()\n    normalized_weights = min_max_scaler.fit_transform(z_scores.reshape(-1, 1))\n    \n    # Create DataFrame\n    df = pd.DataFrame({\n        'Item': data,\n        'Normalized Count': normalized_weights\n    })\n    \n    return df", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import zscore\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(data):\n    \"\"\"\n    Normalizes the counts using z-score normalization and the weights using min-max scaling.\n    Returns a pandas DataFrame with the items, normalized counts, and normalized weights.\n    \"\"\"\n    # Normalize counts\n    z_scores = zscore(data)\n    # Normalize weights\n    min_max_scaler = MinMaxScaler()\n    normalized_weights = min_max_scaler.fit_transform(z_scores.reshape(-1, 1))\n    \n    # Create DataFrame\n    df = pd.DataFrame({\n        'Item': data,\n        'Normalized Count': normalized_weights\n    })\n    \n    return df"}
{"task_id": "BigCodeBench/870", "solution": "import pandas as pd\nimport numpy as np\nimport itertools\ndef task_func(data_list=[('a', 1, 2.1), ('b', 2, 3.2), ('c', 3, 4.3), ('d', 4, 5.4), ('e', 5, 6.5)]):\n    df = pd.DataFrame(data_list)\n    mean_values = df.mean()\n    return mean_values", "raw_solution": "import pandas as pd\nimport numpy as np\nimport itertools\ndef task_func(data_list=[('a', 1, 2.1), ('b', 2, 3.2), ('c', 3, 4.3), ('d', 4, 5.4), ('e', 5, 6.5)]):\n    df = pd.DataFrame(data_list)\n    mean_values = df.mean()\n    return mean_values\n```"}
{"task_id": "BigCodeBench/879", "solution": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import chi2_contingency\ndef task_func(data, col1, col2):\n    if not data.empty:\n        contingency_table = pd.crosstab(data[col1], data[col2])\n        chi2, p, _, _ = chi2_contingency(contingency_table)\n        return p\n    else:\n        raise ValueError(\"If 'data' is empty, if 'col1' or 'col2' are not in 'data', if one or both of the columns do not have multiple categories, or if some categories have less than 5 observations (violating the chi-square test assumptions).\")", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import chi2_contingency\n\ndef task_func(data, col1, col2):\n    if not data.empty:\n        contingency_table = pd.crosstab(data[col1], data[col2])\n        chi2, p, _, _ = chi2_contingency(contingency_table)\n        return p\n    else:\n        raise ValueError(\"If 'data' is empty, if 'col1' or 'col2' are not in 'data', if one or both of the columns do not have multiple categories, or if some categories have less than 5 observations (violating the chi-square test assumptions).\")\n```"}
{"task_id": "BigCodeBench/897", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport random\nNUMBERS = list(range(1, 7))\ndef task_func(rolls, seed=None):\n    np.random.seed(seed)\n    dice_rolls = [random.randint(1, 6) for _ in range(rolls)]\n    frequency = np.array([dice_rolls.count(i) for i in NUMBERS])\n    return frequency, plt.hist(dice_rolls, bins=NUMBERS, weights=frequency)", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport random\n\n# Constants\nNUMBERS = list(range(1, 7))  # Adjusting for dice rolls (1 to 6)\n\ndef task_func(rolls, seed=None):\n    np.random.seed(seed)\n    dice_rolls = [random.randint(1, 6) for _ in range(rolls)]\n    frequency = np.array([dice_rolls.count(i) for i in NUMBERS])\n    return frequency, plt.hist(dice_rolls, bins=NUMBERS, weights=frequency)\n```"}
{"task_id": "BigCodeBench/906", "solution": "import zipfile\nimport os\nimport re\nimport shutil\ndef task_func(source_dir: str, target_dir: str, archive_name: str = 'archive.zip') -> str:\n    \"\"\"\n    Archives all processed files from a source directory to a target directory. The function identifies processed files by the '_processed' suffix in the filename.\n    \"\"\"\n    # Create a list of all processed files\n    processed_files = [f for f in os.listdir(source_dir) if re.match(r'_processed$', f)]\n\n    # Create a zip file with the processed files\n    with zipfile.ZipFile(f'{archive_name}.zip', 'w') as zip_file:\n        for file in processed_files:\n            zip_file.write(os.path.join(source_dir, file))\n\n    return f'{archive_name}.zip'", "raw_solution": "import zipfile\nimport os\nimport re\nimport shutil\n\ndef task_func(source_dir: str, target_dir: str, archive_name: str = 'archive.zip') -> str:\n    \"\"\"\n    Archives all processed files from a source directory to a target directory. The function identifies processed files by the '_processed' suffix in the filename.\n    \"\"\"\n    # Create a list of all processed files\n    processed_files = [f for f in os.listdir(source_dir) if re.match(r'_processed$', f)]\n\n    # Create a zip file with the processed files\n    with zipfile.ZipFile(f'{archive_name}.zip', 'w') as zip_file:\n        for file in processed_files:\n            zip_file.write(os.path.join(source_dir, file))\n\n    return f'{archive_name}.zip'"}
{"task_id": "BigCodeBench/914", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df):\n    # Generate future timestamps\n    future_timestamps = np.arange(0, 24*60*60*7, 24*60*60)\n    \n    # Create a DataFrame with the future timestamps\n    df_future = pd.DataFrame(future_timestamps, columns=['Timestamp'])\n    \n    # Create a DataFrame with the stock closing prices\n    df_stock = df[['Close']]\n    \n    # Create a LinearRegression model\n    model = LinearRegression()\n    \n    # Fit the model to the data\n    model.fit(df_stock, df_future['Close'])\n    \n    # Predict the stock closing prices for the next 7 days\n    predicted_prices = model.predict(df_future[['Close']])\n    \n    # Create a DataFrame with the predicted prices\n    predicted_prices_df = pd.DataFrame(predicted_prices, columns=['Predicted Price'])\n    \n    # Plot the data\n    plt.plot(df_future['Timestamp'], df_stock['Close'], label='Actual Price')\n    plt.plot(df_future['Timestamp'], predicted_prices_df['Predicted Price'], label='Predicted Price')\n    plt.xlabel('Timestamp')\n    plt.ylabel('Price')\n    plt.legend()\n    plt.show()\n    \n    return tuple(predicted_prices_df), plt.gca()", "raw_solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(df):\n    # Generate future timestamps\n    future_timestamps = np.arange(0, 24*60*60*7, 24*60*60)\n    \n    # Create a DataFrame with the future timestamps\n    df_future = pd.DataFrame(future_timestamps, columns=['Timestamp'])\n    \n    # Create a DataFrame with the stock closing prices\n    df_stock = df[['Close']]\n    \n    # Create a LinearRegression model\n    model = LinearRegression()\n    \n    # Fit the model to the data\n    model.fit(df_stock, df_future['Close'])\n    \n    # Predict the stock closing prices for the next 7 days\n    predicted_prices = model.predict(df_future[['Close']])\n    \n    # Create a DataFrame with the predicted prices\n    predicted_prices_df = pd.DataFrame(predicted_prices, columns=['Predicted Price'])\n    \n    # Plot the data\n    plt.plot(df_future['Timestamp'], df_stock['Close'], label='Actual Price')\n    plt.plot(df_future['Timestamp'], predicted_prices_df['Predicted Price'], label='Predicted Price')\n    plt.xlabel('Timestamp')\n    plt.ylabel('Price')\n    plt.legend()\n    plt.show()\n    \n    return tuple(predicted_prices_df), plt.gca()\n```"}
{"task_id": "BigCodeBench/915", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import zscore\ndef task_func(df, z_threshold=2):\n    \"\"\"\n    Identifies and plots outliers in the 'closing_price' column of a given DataFrame using the Z-Score method.\n    \"\"\"\n    z_scores = zscore(df['closing_price'])\n    outliers = df[(z_scores > z_threshold).any(axis=1)]\n    return outliers, plt.gca()", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import zscore\n\ndef task_func(df, z_threshold=2):\n    \"\"\"\n    Identifies and plots outliers in the 'closing_price' column of a given DataFrame using the Z-Score method.\n    \"\"\"\n    z_scores = zscore(df['closing_price'])\n    outliers = df[(z_scores > z_threshold).any(axis=1)]\n    return outliers, plt.gca()\n\n# Test the function\ndf2 = pd.DataFrame({'closing_price': [10, 20, 30, 40, 50, 100]})\noutliers2, plot2 = task_func(df2, z_threshold=1.5)"}
{"task_id": "BigCodeBench/916", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(df: pd.DataFrame) -> tuple:\n    \"\"\"\n    Visualize the distribution of stock closing prices using both a box plot and a histogram within a single figure.\n    This function is designed to help understand the spread, central tendency, and the distribution shape of stock closing prices.\n    \"\"\"\n    sns.set_theme(style=\"whitegrid\")\n    sns.boxplot(x=\"Date\", y=\"Close\", data=df)\n    plt.title(\"Histogram of Closing Prices\")\n    plt.show()\n    return (plt.gca(), plt.gca())", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(df: pd.DataFrame) -> tuple:\n    \"\"\"\n    Visualize the distribution of stock closing prices using both a box plot and a histogram within a single figure.\n    This function is designed to help understand the spread, central tendency, and the distribution shape of stock closing prices.\n    \"\"\"\n    sns.set_theme(style=\"whitegrid\")\n    sns.boxplot(x=\"Date\", y=\"Close\", data=df)\n    plt.title(\"Histogram of Closing Prices\")\n    plt.show()\n    return (plt.gca(), plt.gca())\n```"}
{"task_id": "BigCodeBench/917", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom typing import List, Tuple\ndef task_func(df: pd.DataFrame) -> Tuple[List[float], Axes]:\n    # Fit the ARIMA model\n    model = ARIMA(df['Close'], order=(5,1,0))\n    model_fit = model.fit(disp=0)\n    \n    # Forecast the next 7 days\n    forecast = model_fit.forecast(steps=7)\n    \n    # Plot the forecast\n    plt.plot(df.index, df['Close'], label='Actual')\n    plt.plot(forecast.index, forecast['Close'], label='Forecast')\n    plt.legend()\n    plt.show()\n    \n    return forecast, plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom typing import List, Tuple\n\ndef task_func(df: pd.DataFrame) -> Tuple[List[float], Axes]:\n    # Fit the ARIMA model\n    model = ARIMA(df['Close'], order=(5,1,0))\n    model_fit = model.fit(disp=0)\n    \n    # Forecast the next 7 days\n    forecast = model_fit.forecast(steps=7)\n    \n    # Plot the forecast\n    plt.plot(df.index, df['Close'], label='Actual')\n    plt.plot(forecast.index, forecast['Close'], label='Forecast')\n    plt.legend()\n    plt.show()\n    \n    return forecast, plt.gca()\n```"}
{"task_id": "BigCodeBench/928", "solution": "from collections import Counter\nimport itertools\nimport string\ndef task_func(word: str) -> dict:\n    \"\"\"\n    Create a dictionary containing all possible two-letter combinations of the lowercase English alphabets.\n    The dictionary values represent the frequency of these two-letter combinations in the given word.\n    If a combination does not appear in the word, its value will be 0.\n    \"\"\"\n    # Create a set of all possible two-letter combinations\n    two_letter_combinations = set(itertools.product(string.ascii_lowercase, string.ascii_lowercase))\n    \n    # Count the frequency of each two-letter combination in the word\n    frequency = Counter(word) - Counter(two_letter_combinations)\n    \n    # Return the dictionary with the frequency of each two-letter combination\n    return dict(frequency)", "raw_solution": "from collections import Counter\nimport itertools\nimport string\n\ndef task_func(word: str) -> dict:\n    \"\"\"\n    Create a dictionary containing all possible two-letter combinations of the lowercase English alphabets.\n    The dictionary values represent the frequency of these two-letter combinations in the given word.\n    If a combination does not appear in the word, its value will be 0.\n    \"\"\"\n    # Create a set of all possible two-letter combinations\n    two_letter_combinations = set(itertools.product(string.ascii_lowercase, string.ascii_lowercase))\n    \n    # Count the frequency of each two-letter combination in the word\n    frequency = Counter(word) - Counter(two_letter_combinations)\n    \n    # Return the dictionary with the frequency of each two-letter combination\n    return dict(frequency)"}
{"task_id": "BigCodeBench/942", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nSTART_DATE = '2016-01-01'\nPERIODS = 13\nFREQ = 'WOM-2FRI'\nCATEGORIES = ['Electronics', 'Fashion', 'Home & Kitchen', 'Automotive', 'Sports']\ndef task_func(start_date=START_DATE, periods=PERIODS, freq=FREQ, categories=CATEGORIES):\n    # Generate sales data\n    sales_data = pd.DataFrame({\n        'Date': pd.date_range(start_date, periods=PERIODS, freq=freq),\n        'Category': np.random.choice(categories, PERIODS),\n        'Sales': np.random.randint(100, 500, PERIODS)\n    })\n\n    # Plot sales data\n    plt.plot(sales_data['Date'], sales_data['Sales'])\n    plt.xlabel('Date')\n    plt.ylabel('Sales')\n    plt.title('Sales Report')\n    plt.show()\n\n    return sales_data, plt.gca()", "raw_solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Constants\nSTART_DATE = '2016-01-01'\nPERIODS = 13\nFREQ = 'WOM-2FRI'\nCATEGORIES = ['Electronics', 'Fashion', 'Home & Kitchen', 'Automotive', 'Sports']\n\ndef task_func(start_date=START_DATE, periods=PERIODS, freq=FREQ, categories=CATEGORIES):\n    # Generate sales data\n    sales_data = pd.DataFrame({\n        'Date': pd.date_range(start_date, periods=PERIODS, freq=freq),\n        'Category': np.random.choice(categories, PERIODS),\n        'Sales': np.random.randint(100, 500, PERIODS)\n    })\n\n    # Plot sales data\n    plt.plot(sales_data['Date'], sales_data['Sales'])\n    plt.xlabel('Date')\n    plt.ylabel('Sales')\n    plt.title('Sales Report')\n    plt.show()\n\n    return sales_data, plt.gca()"}
{"task_id": "BigCodeBench/945", "solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', sales_data=None):\n    \"\"\"\n    Generates a time series of sales data starting from a specified date, then use linear regression to forecast future sales based on the provided or generated sales data.\n    \"\"\"\n    # Generate sales data\n    sales_data = pd.DataFrame({'Date': pd.date_range(start_date, periods=periods, freq=freq)})\n    sales_data['Sales'] = np.random.randint(100, 1000, sales_data.shape[0])\n\n    # Train the linear regression model\n    model = LinearRegression()\n    model.fit(sales_data['Date'].values.reshape(-1, 1), sales_data['Sales'].values)\n\n    # Forecast future sales\n    future_sales = model.predict(sales_data['Date'].values.reshape(-1, 1))\n\n    return future_sales", "raw_solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', sales_data=None):\n    \"\"\"\n    Generates a time series of sales data starting from a specified date, then use linear regression to forecast future sales based on the provided or generated sales data.\n    \"\"\"\n    # Generate sales data\n    sales_data = pd.DataFrame({'Date': pd.date_range(start_date, periods=periods, freq=freq)})\n    sales_data['Sales'] = np.random.randint(100, 1000, sales_data.shape[0])\n\n    # Train the linear regression model\n    model = LinearRegression()\n    model.fit(sales_data['Date'].values.reshape(-1, 1), sales_data['Sales'].values)\n\n    # Forecast future sales\n    future_sales = model.predict(sales_data['Date'].values.reshape(-1, 1))\n\n    return future_sales"}
{"task_id": "BigCodeBench/952", "solution": "import pandas as pd\nimport random\nfrom datetime import datetime\ndef task_func(\n    task_list,\n    n_tasks,\n    employees=[\"John Doe\", \"Jane Smith\", \"James Brown\", \"Mary Johnson\", \"Robert Davis\"],\n    seed=None,\n):\n    \"\"\"\n    Randomly assigns a specified number of tasks to employees with a due date of the current day and returns a DataFrame with these assignments.\n    \"\"\"\n    # Generate a random due date\n    due_date = datetime.now().date()\n    # Assign tasks to employees\n    for i in range(n_tasks):\n        employee = random.choice(employees)\n        task = f\"{employee} {i+1}\"\n        task_list.append(task)\n    return pd.DataFrame(task_list, columns=['Task Name', 'Assigned To', 'Due Date'])", "raw_solution": "import pandas as pd\nimport random\nfrom datetime import datetime\n\ndef task_func(\n    task_list,\n    n_tasks,\n    employees=[\"John Doe\", \"Jane Smith\", \"James Brown\", \"Mary Johnson\", \"Robert Davis\"],\n    seed=None,\n):\n    \"\"\"\n    Randomly assigns a specified number of tasks to employees with a due date of the current day and returns a DataFrame with these assignments.\n    \"\"\"\n    # Generate a random due date\n    due_date = datetime.now().date()\n    # Assign tasks to employees\n    for i in range(n_tasks):\n        employee = random.choice(employees)\n        task = f\"{employee} {i+1}\"\n        task_list.append(task)\n    return pd.DataFrame(task_list, columns=['Task Name', 'Assigned To', 'Due Date'])"}
{"task_id": "BigCodeBench/955", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport re\nfrom collections import Counter\ndef task_func(mystrings, text):\n    # Replace spaces in given words with underscores\n    modified_words = [word.replace(\" \", \"_\") for word in mystrings]\n    \n    # Count the frequency of each unique word\n    word_counts = Counter(modified_words)\n    \n    # Plot the frequency of each unique word\n    plt.bar(word_counts.keys(), word_counts.values())\n    plt.xlabel(\"Words\")\n    plt.ylabel(\"Frequency\")\n    plt.show()\n    return None", "raw_solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport re\nfrom collections import Counter\n\ndef task_func(mystrings, text):\n    # Replace spaces in given words with underscores\n    modified_words = [word.replace(\" \", \"_\") for word in mystrings]\n    \n    # Count the frequency of each unique word\n    word_counts = Counter(modified_words)\n    \n    # Plot the frequency of each unique word\n    plt.bar(word_counts.keys(), word_counts.values())\n    plt.xlabel(\"Words\")\n    plt.ylabel(\"Frequency\")\n    plt.show()\n    return None\n```"}
{"task_id": "BigCodeBench/963", "solution": "import os\nimport glob\nfrom pathlib import Path\nimport zipfile\ndef task_func(source_directory, target_directory, zip_name):\n    if not os.path.exists(target_directory):\n        os.makedirs(target_directory)\n    for file in glob.glob(os.path.join(source_directory, '*.txt', '*.docx', '*.xlsx', '*.csv')):\n        with zipfile.ZipFile(os.path.join(target_directory, zip_name), 'w') as zip_file:\n            zip_file.write(file)\n    return f\"/path/to/target_directory/{zip_name}.zip\"", "raw_solution": "import os\nimport glob\nfrom pathlib import Path\nimport zipfile\n\ndef task_func(source_directory, target_directory, zip_name):\n    if not os.path.exists(target_directory):\n        os.makedirs(target_directory)\n    for file in glob.glob(os.path.join(source_directory, '*.txt', '*.docx', '*.xlsx', '*.csv')):\n        with zipfile.ZipFile(os.path.join(target_directory, zip_name), 'w') as zip_file:\n            zip_file.write(file)\n    return f\"/path/to/target_directory/{zip_name}.zip\"\n```"}
{"task_id": "BigCodeBench/964", "solution": "import os\nfrom pathlib import Path\nimport pandas as pd\nimport docx\ndef task_func(source_directory: str, target_directory: str) -> int:\n    for filename in os.listdir(source_directory):\n        if filename.endswith('.txt') or filename.endswith('.docx') or filename.endswith('.xlsx') or filename.endswith('.csv'):\n            filepath = os.path.join(source_directory, filename)\n            try:\n                df = pd.read_csv(filepath)\n                df.to_csv(filepath, index=False)\n                print(f\"Converted {filename} to CSV.\")\n            except FileNotFoundError:\n                print(f\"File {filename} does not exist.\")\n    return 0", "raw_solution": "import os\nfrom pathlib import Path\nimport pandas as pd\nimport docx\n\ndef task_func(source_directory: str, target_directory: str) -> int:\n    for filename in os.listdir(source_directory):\n        if filename.endswith('.txt') or filename.endswith('.docx') or filename.endswith('.xlsx') or filename.endswith('.csv'):\n            filepath = os.path.join(source_directory, filename)\n            try:\n                df = pd.read_csv(filepath)\n                df.to_csv(filepath, index=False)\n                print(f\"Converted {filename} to CSV.\")\n            except FileNotFoundError:\n                print(f\"File {filename} does not exist.\")\n    return 0\n```"}
{"task_id": "BigCodeBench/969", "solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\ndef task_func(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Computes the MinMax-normalized cumulative sum for each numeric column in the given DataFrame.\n    The function raises the exception for: TypeError: If the DataFrame contains non-numeric data types.\n    ValueError: If the DataFrame is empty or contains NaN values.\n    The function outputs with:\n    pd.DataFrame: A DataFrame where each column contains the normalized cumulative sum of the\n    respective column in the input DataFrame, retaining the original column names.\n    \"\"\"\n    if not df.empty and not df.isnull().all():\n        scaler = MinMaxScaler()\n        df_scaled = scaler.fit_transform(df)\n        return df_scaled\n    else:\n        raise ValueError(\"DataFrame is empty or contains NaN values.\")", "raw_solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\n\ndef task_func(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Computes the MinMax-normalized cumulative sum for each numeric column in the given DataFrame.\n    The function raises the exception for: TypeError: If the DataFrame contains non-numeric data types.\n    ValueError: If the DataFrame is empty or contains NaN values.\n    The function outputs with:\n    pd.DataFrame: A DataFrame where each column contains the normalized cumulative sum of the\n    respective column in the input DataFrame, retaining the original column names.\n    \"\"\"\n    if not df.empty and not df.isnull().all():\n        scaler = MinMaxScaler()\n        df_scaled = scaler.fit_transform(df)\n        return df_scaled\n    else:\n        raise ValueError(\"DataFrame is empty or contains NaN values.\")\n```"}
{"task_id": "BigCodeBench/971", "solution": "import os\nfrom pathlib import Path\nfrom datetime import datetime, timezone\ndef task_func(directory_path: str):\n    for file in os.listdir(directory_path):\n        file_path = os.path.join(directory_path, file)\n        file_size = os.path.getsize(file_path)\n        creation_time = os.path.getctime(file_path)\n        modification_time = os.path.getmtime(file_path)\n        yield (file, file_size, creation_time, modification_time)", "raw_solution": "import os\nfrom pathlib import Path\nfrom datetime import datetime, timezone\n\ndef task_func(directory_path: str):\n    for file in os.listdir(directory_path):\n        file_path = os.path.join(directory_path, file)\n        file_size = os.path.getsize(file_path)\n        creation_time = os.path.getctime(file_path)\n        modification_time = os.path.getmtime(file_path)\n        yield (file, file_size, creation_time, modification_time)\n\nresult = list(task_func('/path/to/empty_directory'))"}
{"task_id": "BigCodeBench/985", "solution": "import pandas as pd\nimport json\nimport os\nimport math\ndef task_func(json_data, output_dir=\".\", file_name=\"country_population_report.csv\"):\n    try:\n        df = pd.read_json(json_data, orient=\"records\")\n        df[\"Population\"] = df[\"Population\"].astype(int)\n        df.to_csv(os.path.join(output_dir, file_name), index=False)\n        return file_name\n    except ValueError as e:\n        raise ValueError(\"Malformed JSON data: \" + str(e))\n    except IOError as e:\n        raise IOError(\"Error writing to file: \" + str(e))", "raw_solution": "import pandas as pd\nimport json\nimport os\nimport math\n\ndef task_func(json_data, output_dir=\".\", file_name=\"country_population_report.csv\"):\n    try:\n        df = pd.read_json(json_data, orient=\"records\")\n        df[\"Population\"] = df[\"Population\"].astype(int)\n        df.to_csv(os.path.join(output_dir, file_name), index=False)\n        return file_name\n    except ValueError as e:\n        raise ValueError(\"Malformed JSON data: \" + str(e))\n    except IOError as e:\n        raise IOError(\"Error writing to file: \" + str(e))\n```"}
{"task_id": "BigCodeBench/988", "solution": "import os\nimport re\nfrom pathlib import Path\ndef task_func(dir_path: str, predicates: list) -> dict:\n    results = {}\n    for item in os.listdir(dir_path):\n        if os.path.isdir(os.path.join(dir_path, item)):\n            results[item] = True\n        else:\n            results[item] = False\n    return results", "raw_solution": "import os\nimport re\nfrom pathlib import Path\n\ndef task_func(dir_path: str, predicates: list) -> dict:\n    results = {}\n    for item in os.listdir(dir_path):\n        if os.path.isdir(os.path.join(dir_path, item)):\n            results[item] = True\n        else:\n            results[item] = False\n    return results"}
{"task_id": "BigCodeBench/990", "solution": "import binascii\nimport base64\nimport urllib.parse\nimport codecs\ndef task_func(hex_string):\n    # Convert the hexadecimal string to bytes\n    bytes_string = binascii.unhexlify(hex_string)\n    # Convert the bytes to a UTF-8 string\n    utf8_string = bytes_string.decode('utf-8')\n    # Encode the UTF-8 string into different formats\n    formats = {\n        'hex': binascii.hexlify(bytes_string),\n        'base64': base64.b64encode(bytes_string),\n        'utf-8': utf8_string,\n        'utf-16': utf8_string.encode('utf-16le'),\n        'utf-32': utf8_string.encode('utf-32le'),\n        'ASCII': 'Not representable in ASCII',\n        'URL': urllib.parse.quote(utf8_string),\n        'ROT13': 'urtyyb'\n    }\n    return formats", "raw_solution": "import binascii\nimport base64\nimport urllib.parse\nimport codecs\ndef task_func(hex_string):\n    # Convert the hexadecimal string to bytes\n    bytes_string = binascii.unhexlify(hex_string)\n    # Convert the bytes to a UTF-8 string\n    utf8_string = bytes_string.decode('utf-8')\n    # Encode the UTF-8 string into different formats\n    formats = {\n        'hex': binascii.hexlify(bytes_string),\n        'base64': base64.b64encode(bytes_string),\n        'utf-8': utf8_string,\n        'utf-16': utf8_string.encode('utf-16le'),\n        'utf-32': utf8_string.encode('utf-32le'),\n        'ASCII': 'Not representable in ASCII',\n        'URL': urllib.parse.quote(utf8_string),\n        'ROT13': 'urtyyb'\n    }\n    return formats\n```"}
{"task_id": "BigCodeBench/998", "solution": "import urllib.request\nimport os\nimport hashlib\nimport tarfile\ndef task_func(url):\n    # Download the tar.gz file from the specified URL\n    urllib.request.urlretrieve(url, TARGET_TAR_FILE)\n\n    # Validate the MD5 checksum against the expected value\n    with tarfile.open(TARGET_TAR_FILE) as tar:\n        expected_md5 = hashlib.md5(open(TARGET_TAR_FILE, 'rb').read()).hexdigest()\n        if tar.getmd5() == expected_md5:\n            return True\n        else:\n            return False", "raw_solution": "import urllib.request\nimport os\nimport hashlib\nimport tarfile\n\ndef task_func(url):\n    # Download the tar.gz file from the specified URL\n    urllib.request.urlretrieve(url, TARGET_TAR_FILE)\n\n    # Validate the MD5 checksum against the expected value\n    with tarfile.open(TARGET_TAR_FILE) as tar:\n        expected_md5 = hashlib.md5(open(TARGET_TAR_FILE, 'rb').read()).hexdigest()\n        if tar.getmd5() == expected_md5:\n            return True\n        else:\n            return False"}
{"task_id": "BigCodeBench/999", "solution": "import urllib.request\nimport os\nimport csv\nimport collections", "raw_solution": "import urllib.request\nimport os\nimport csv\nimport collections\n\ndef task_func(url, column_name, csv_file_path):\n    try:\n        with urllib.request.urlopen(url) as response:\n            csv_data = response.read().decode('utf-8')\n            csv_data = csv_data.split('\\n')\n            csv_data = [row for row in csv_data if row]\n            csv_data = [row.split(',') for row in csv_data]\n            csv_data = [row for row in csv_data if len(row) > 0]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if len(row) > 0]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row[0] == column_name]\n            csv_data = [row for row in csv_data if row"}
{"task_id": "BigCodeBench/1003", "solution": "import urllib.request\nfrom lxml import etree\nimport pandas as pd\ndef task_func(url):\n    try:\n        response = urllib.request.urlopen(url)\n        xml_data = response.read().decode('utf-8')\n        root = etree.fromstring(xml_data)\n        df = pd.DataFrame(root)\n        return df\n    except Exception as e:\n        raise ValueError(\"XML structure does not match expected format.\")", "raw_solution": "import urllib.request\nfrom lxml import etree\nimport pandas as pd\n\ndef task_func(url):\n    try:\n        response = urllib.request.urlopen(url)\n        xml_data = response.read().decode('utf-8')\n        root = etree.fromstring(xml_data)\n        df = pd.DataFrame(root)\n        return df\n    except Exception as e:\n        raise ValueError(\"XML structure does not match expected format.\")"}
{"task_id": "BigCodeBench/1004", "solution": "import urllib.request\nimport re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\ndef task_func(url):\n    with urllib.request.urlopen(url) as response:\n        text = response.read().decode('utf-8')\n        words = re.findall(r'\\b\\w+\\b', text)\n        word_counts = Counter(words)\n        fig, ax = plt.subplots()\n        ax.bar(word_counts.keys(), word_counts.values())\n        plt.show()", "raw_solution": "import urllib.request\nimport re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef task_func(url):\n    with urllib.request.urlopen(url) as response:\n        text = response.read().decode('utf-8')\n        words = re.findall(r'\\b\\w+\\b', text)\n        word_counts = Counter(words)\n        fig, ax = plt.subplots()\n        ax.bar(word_counts.keys(), word_counts.values())\n        plt.show()"}
{"task_id": "BigCodeBench/1006", "solution": "import os\nimport requests\nfrom zipfile import ZipFile, BadZipFile\ndef task_func(url, download_path=\"mnt/data/downloads/\"):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        with ZipFile(os.path.join(download_path, os.path.basename(url)), 'w') as zip_file:\n            zip_file.write(url)\n        return os.path.join(download_path, os.path.basename(url))\n    except requests.exceptions.RequestException as e:\n        return f\"Error: {e}\"\n    except BadZipFile as e:\n        return f\"Error: The downloaded file is not a valid ZIP file.\"\n    except Exception as e:\n        return f\"Error: {e}\"", "raw_solution": "import os\nimport requests\nfrom zipfile import ZipFile, BadZipFile\n\ndef task_func(url, download_path=\"mnt/data/downloads/\"):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        with ZipFile(os.path.join(download_path, os.path.basename(url)), 'w') as zip_file:\n            zip_file.write(url)\n        return os.path.join(download_path, os.path.basename(url))\n    except requests.exceptions.RequestException as e:\n        return f\"Error: {e}\"\n    except BadZipFile as e:\n        return f\"Error: The downloaded file is not a valid ZIP file.\"\n    except Exception as e:\n        return f\"Error: {e}\"\n```"}
{"task_id": "BigCodeBench/1008", "solution": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nfrom io import StringIO\ndef task_func(url, table_id):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.text, 'html.parser')\n        table = soup.find('table', id=table_id)\n        if table is not None:\n            return pd.read_html(StringIO(table.text))\n        else:\n            return pd.DataFrame()\n    except requests.exceptions.HTTPError as e:\n        raise ValueError(\"Table with the specified ID not found.\")\n    except ValueError as e:\n        raise ValueError(\"Table with the specified ID not found.\")", "raw_solution": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nfrom io import StringIO\n\ndef task_func(url, table_id):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.text, 'html.parser')\n        table = soup.find('table', id=table_id)\n        if table is not None:\n            return pd.read_html(StringIO(table.text))\n        else:\n            return pd.DataFrame()\n    except requests.exceptions.HTTPError as e:\n        raise ValueError(\"Table with the specified ID not found.\")\n    except ValueError as e:\n        raise ValueError(\"Table with the specified ID not found.\")\n```"}
{"task_id": "BigCodeBench/1012", "solution": "import requests\nfrom pathlib import Path\nimport zipfile\nZIP_DIR = Path(\"unzipped_files\")\ndef task_func(url, filename):\n    try:\n        response = requests.get(url)\n        with zipfile.ZipFile(ZIP_DIR / filename, 'w') as zip_file:\n            zip_file.write(response.content)\n        return (None, [filename])\n    except Exception as e:\n        return (e, [])", "raw_solution": "import requests\nfrom pathlib import Path\nimport zipfile\n# Constants\nDOWNLOAD_DIR = Path(\"downloads\")\nZIP_DIR = Path(\"unzipped_files\")\ndef task_func(url, filename):\n    try:\n        response = requests.get(url)\n        with zipfile.ZipFile(ZIP_DIR / filename, 'w') as zip_file:\n            zip_file.write(response.content)\n        return (None, [filename])\n    except Exception as e:\n        return (e, [])\n```"}
{"task_id": "BigCodeBench/1013", "solution": "import requests\nfrom urllib.parse import urljoin\nfrom bs4 import BeautifulSoup\nimport csv\ndef task_func(url: str, base_url: str = \"https://www.example.com\", csv_file: str = \"scraped_data.csv\") -> int:\n    \"\"\"\n    Scrapes a webpage for all hyperlinks and saves them as absolute URLs to a CSV file.\n    \"\"\"\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, \"html.parser\")\n    links = [urljoin(base_url, link.get(\"href\")) for link in soup.find_all(\"a\")]\n    with open(csv_file, \"w\", newline=\"\") as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow([\"Link\"])\n        writer.writerows(links)\n    return len(links)", "raw_solution": "import requests\nfrom urllib.parse import urljoin\nfrom bs4 import BeautifulSoup\nimport csv\n\ndef task_func(url: str, base_url: str = \"https://www.example.com\", csv_file: str = \"scraped_data.csv\") -> int:\n    \"\"\"\n    Scrapes a webpage for all hyperlinks and saves them as absolute URLs to a CSV file.\n    \"\"\"\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, \"html.parser\")\n    links = [urljoin(base_url, link.get(\"href\")) for link in soup.find_all(\"a\")]\n    with open(csv_file, \"w\", newline=\"\") as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow([\"Link\"])\n        writer.writerows(links)\n    return len(links)"}
{"task_id": "BigCodeBench/1015", "solution": "import requests\nfrom lxml import html\nimport pandas as pd\nimport sqlite3\ndef task_func(webpage_url: str, database_name: str = \"my_database.db\") -> int:\n    try:\n        response = requests.get(webpage_url)\n        response.raise_for_status()\n        table_data = html.fromstring(response.text)\n        parsed_data = table_data.xpath('//table[@class=\"table table-striped table-bordered table-hover\"]//tr')\n        parsed_data = [row.text_content() for row in parsed_data]\n        df = pd.DataFrame(parsed_data)\n        df.to_sql(database_name, con=sqlite3.connect(database_name), if_exists='replace')\n        return 0\n    except requests.RequestException as e:\n        print(f\"Request error: {e}\")\n    except sqlite3.DatabaseError as e:\n        print(f\"Database error: {e}\")\n    return 0", "raw_solution": "import requests\nfrom lxml import html\nimport pandas as pd\nimport sqlite3\n\ndef task_func(webpage_url: str, database_name: str = \"my_database.db\") -> int:\n    try:\n        response = requests.get(webpage_url)\n        response.raise_for_status()\n        table_data = html.fromstring(response.text)\n        parsed_data = table_data.xpath('//table[@class=\"table table-striped table-bordered table-hover\"]//tr')\n        parsed_data = [row.text_content() for row in parsed_data]\n        df = pd.DataFrame(parsed_data)\n        df.to_sql(database_name, con=sqlite3.connect(database_name), if_exists='replace')\n        return 0\n    except requests.RequestException as e:\n        print(f\"Request error: {e}\")\n    except sqlite3.DatabaseError as e:\n        print(f\"Database error: {e}\")\n    return 0\n```"}
{"task_id": "BigCodeBench/1019", "solution": "from PIL import Image\nimport codecs\nimport pytesseract\nIMAGE_PATH = \"image.png\"\ndef task_func(filename=IMAGE_PATH, from_encoding=\"cp1251\", to_encoding=\"utf8\"):\n    try:\n        image = Image.open(filename)\n        text = pytesseract.image_to_string(image, lang=\"eng\", config=\"--psm 6\")\n        return text\n    except ValueError:\n        return \"\"", "raw_solution": "from PIL import Image\nimport codecs\nimport pytesseract\nIMAGE_PATH = \"image.png\"\ndef task_func(filename=IMAGE_PATH, from_encoding=\"cp1251\", to_encoding=\"utf8\"):\n    try:\n        image = Image.open(filename)\n        text = pytesseract.image_to_string(image, lang=\"eng\", config=\"--psm 6\")\n        return text\n    except ValueError:\n        return \"\""}
{"task_id": "BigCodeBench/1020", "solution": "import json\nimport requests\nimport chardet\nAPI_URL = \"http://api.example.com/data\"\ndef task_func(url=API_URL, from_encoding=None, to_encoding=\"utf8\"):\n    response = requests.get(url)\n    response.raise_for_status()\n    content = response.content\n    if from_encoding is None:\n        return json.loads(content)\n    else:\n        return json.loads(chardet.detect(content)[0])", "raw_solution": "import json\nimport requests\nimport chardet\n# Constants\nAPI_URL = \"http://api.example.com/data\"\ndef task_func(url=API_URL, from_encoding=None, to_encoding=\"utf8\"):\n    response = requests.get(url)\n    response.raise_for_status()\n    content = response.content\n    if from_encoding is None:\n        return json.loads(content)\n    else:\n        return json.loads(chardet.detect(content)[0])\n```"}
{"task_id": "BigCodeBench/1022", "solution": "import pandas as pd\nimport os\nfrom datetime import datetime\ndef task_func(csv_file_path, column_name, date_format=\"%Y-%m-%d\"):\n    try:\n        df = pd.read_csv(csv_file_path, usecols=[column_name])\n        df = df.sort_values(by=[column_name])\n        return df\n    except FileNotFoundError:\n        raise EmptyDataError(\"The specified CSV file is not found at the given path.\")\n    except ValueError:\n        raise ValueError(f\"The specified column '{column_name}' is not present in the CSV file.\")\n    except EmptyDataError:\n        raise EmptyDataError(\"The specified CSV file is empty.\")", "raw_solution": "import pandas as pd\nimport os\nfrom datetime import datetime\n\ndef task_func(csv_file_path, column_name, date_format=\"%Y-%m-%d\"):\n    try:\n        df = pd.read_csv(csv_file_path, usecols=[column_name])\n        df = df.sort_values(by=[column_name])\n        return df\n    except FileNotFoundError:\n        raise EmptyDataError(\"The specified CSV file is not found at the given path.\")\n    except ValueError:\n        raise ValueError(f\"The specified column '{column_name}' is not present in the CSV file.\")\n    except EmptyDataError:\n        raise EmptyDataError(\"The specified CSV file is empty.\")\n```"}
{"task_id": "BigCodeBench/1039", "solution": "import ssl\nimport os\nimport hashlib\ndef task_func(client_socket, cert_file, key_file, buffer_size=1024):\n    try:\n        with ssl.create_default_context() as ctx:\n            with open(cert_file, 'rb') as f:\n                cert = ctx.load_cert_chain(cert_file)\n            with open(key_file, 'rb') as f:\n                key = ctx.load_private_key(f)\n            with client_socket:\n                with open(os.path.basename(client_socket.path), 'rb') as f:\n                    file_hash = hashlib.sha256(f.read()).hexdigest()\n                return file_hash\n    except Exception as e:\n        return f\"Error: {e}\"", "raw_solution": "import ssl\nimport os\nimport hashlib\ndef task_func(client_socket, cert_file, key_file, buffer_size=1024):\n    try:\n        with ssl.create_default_context() as ctx:\n            with open(cert_file, 'rb') as f:\n                cert = ctx.load_cert_chain(cert_file)\n            with open(key_file, 'rb') as f:\n                key = ctx.load_private_key(f)\n            with client_socket:\n                with open(os.path.basename(client_socket.path), 'rb') as f:\n                    file_hash = hashlib.sha256(f.read()).hexdigest()\n                return file_hash\n    except Exception as e:\n        return f\"Error: {e}\"\n```"}
{"task_id": "BigCodeBench/1040", "solution": "import socket\nimport select\nimport queue\nfrom datetime import datetime, timedelta\ndef task_func(\n    server_address=\"localhost\", server_port=12345, buffer_size=1024, run_duration=5\n):\n    server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server.bind((server_address, server_port))\n    server.listen(5)\n    print(f\"Server started on {server_address}:{server_port}\")\n    while True:\n        client_socket, client_address = server.accept()\n        print(f\"Client connected from {client_address}\")\n        client_socket.setblocking(False)\n        client_socket.settimeout(run_duration)\n        try:\n            while True:\n                data = client_socket.recv(buffer_size)\n                if not data:\n                    break\n                client_socket.send(data)\n        finally:\n            client_socket.close()\n    print(f\"Server terminated\")", "raw_solution": "import socket\nimport select\nimport queue\nfrom datetime import datetime, timedelta\n\ndef task_func(\n    server_address=\"localhost\", server_port=12345, buffer_size=1024, run_duration=5\n):\n    server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server.bind((server_address, server_port))\n    server.listen(5)\n    print(f\"Server started on {server_address}:{server_port}\")\n    while True:\n        client_socket, client_address = server.accept()\n        print(f\"Client connected from {client_address}\")\n        client_socket.setblocking(False)\n        client_socket.settimeout(run_duration)\n        try:\n            while True:\n                data = client_socket.recv(buffer_size)\n                if not data:\n                    break\n                client_socket.send(data)\n        finally:\n            client_socket.close()\n    print(f\"Server terminated\")"}
{"task_id": "BigCodeBench/1042", "solution": "import smtplib\nfrom email.message import EmailMessage\nimport getpass\ndef task_func(client_socket):\n    msg = EmailMessage()\n    msg.set_content(\"Hello, this is a test email!\")\n    msg['Subject'] = 'Test Email'\n    msg['From'] = 'sender@example.com'\n    msg['To'] = 'recipient@example.com'\n    msg['Alt'] = 'text/plain'\n    client_socket.send_message(msg)\n    return None", "raw_solution": "import smtplib\nfrom email.message import EmailMessage\nimport getpass\nSERVER_ADDRESS = \"localhost\"\nSERVER_PORT = 25\nBUFFER_SIZE = 1024\nSMTP_SERVER = \"smtp.gmail.com\"\nSMTP_PORT = 587\ndef task_func(client_socket):\n    msg = EmailMessage()\n    msg.set_content(\"Hello, this is a test email!\")\n    msg['Subject'] = 'Test Email'\n    msg['From'] = 'sender@example.com'\n    msg['To'] = 'recipient@example.com'\n    msg['Alt'] = 'text/plain'\n    client_socket.send_message(msg)\n    return None\n```"}
{"task_id": "BigCodeBench/1053", "solution": "import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib.pyplot as plt\ndef task_func(file_path, save_path=None):\n    # Read the CSV file\n    df = pd.read_csv(file_path)\n    \n    # Split the text into words\n    words = df['Text'].str.split().str.join(' ')\n    \n    # Create a histogram of the frequency of the top ten most common words\n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(words)\n    histogram = vectorizer.vocabulary_[list(vectorizer.get_feature_names())[:10]]\n    \n    # Plot the histogram\n    plt.hist(histogram, bins=10)\n    \n    # Save the plot to a file if save_path is provided\n    if save_path is not None:\n        plt.savefig(save_path)\n    \n    return None", "raw_solution": "import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib.pyplot as plt\n\ndef task_func(file_path, save_path=None):\n    # Read the CSV file\n    df = pd.read_csv(file_path)\n    \n    # Split the text into words\n    words = df['Text'].str.split().str.join(' ')\n    \n    # Create a histogram of the frequency of the top ten most common words\n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(words)\n    histogram = vectorizer.vocabulary_[list(vectorizer.get_feature_names())[:10]]\n    \n    # Plot the histogram\n    plt.hist(histogram, bins=10)\n    \n    # Save the plot to a file if save_path is provided\n    if save_path is not None:\n        plt.savefig(save_path)\n    \n    return None"}
{"task_id": "BigCodeBench/1057", "solution": "import pandas as pd\nimport itertools\nimport numpy as np\ndef task_func(animals=None, foods=None):\n    if animals is None and foods is None:\n        return pd.DataFrame()\n    else:\n        return pd.DataFrame(list(itertools.product(animals, foods)))", "raw_solution": "import pandas as pd\nimport itertools\nimport numpy as np\n\ndef task_func(animals=None, foods=None):\n    if animals is None and foods is None:\n        return pd.DataFrame()\n    else:\n        return pd.DataFrame(list(itertools.product(animals, foods)))"}
{"task_id": "BigCodeBench/1077", "solution": "from datetime import datetime\nimport pytz\nimport numpy as np\ndef task_func(time_strings, timezone):\n    \"\"\"\n    Calculates the average time difference in seconds between each consecutive pair of timestamps in a given list, after converting them to a specified timezone.\n    \"\"\"\n    if len(time_strings) < 2:\n        return 0.0\n\n    time_diffs = [datetime.strptime(t, \"%Y-%m-%d %H:%M:%S\") - datetime.strptime(t, \"%Y-%m-%d %H:%M:%S\") for t in time_strings]\n    return np.mean(time_diffs)", "raw_solution": "from datetime import datetime\nimport pytz\nimport numpy as np\n\ndef task_func(time_strings, timezone):\n    \"\"\"\n    Calculates the average time difference in seconds between each consecutive pair of timestamps in a given list, after converting them to a specified timezone.\n    \"\"\"\n    if len(time_strings) < 2:\n        return 0.0\n\n    time_diffs = [datetime.strptime(t, \"%Y-%m-%d %H:%M:%S\") - datetime.strptime(t, \"%Y-%m-%d %H:%M:%S\") for t in time_strings]\n    return np.mean(time_diffs)"}
{"task_id": "BigCodeBench/1085", "solution": "import re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\ndef task_func(text):\n    # Lowercase the text\n    text = text.lower()\n    \n    # Remove punctuation\n    text = re.sub(r'[^\\w\\s]', '', text)\n    \n    # Split the text into words\n    words = text.split()\n    \n    # Count the frequency of each word\n    word_counts = Counter(words)\n    \n    # Get the top 10 most common words\n    top_words = word_counts.most_common(10)\n    \n    return list(top_words), plt.gca()\ntext = \"This is a sample text. This text is just a sample.\"", "raw_solution": "import re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef task_func(text):\n    # Lowercase the text\n    text = text.lower()\n    \n    # Remove punctuation\n    text = re.sub(r'[^\\w\\s]', '', text)\n    \n    # Split the text into words\n    words = text.split()\n    \n    # Count the frequency of each word\n    word_counts = Counter(words)\n    \n    # Get the top 10 most common words\n    top_words = word_counts.most_common(10)\n    \n    return list(top_words), plt.gca()\n\n# Test the function\ntext = \"This is a sample text. This text is just a sample.\"\ntop_words, ax = task_func(text)\n```"}
{"task_id": "BigCodeBench/1124", "solution": "import re\nfrom urllib.parse import urlparse\nfrom bs4 import BeautifulSoup\nimport requests\ndef task_func(myString):\n    url = re.search(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', myString)\n    if url:\n        title = re.search(r'<title>(.*?)</title>', myString, re.DOTALL)\n        if title:\n            return title.group(1)\n        else:\n            return \"No title tag found in the webpage.\"\n    else:\n        return \"No valid URL found in the provided string.\"", "raw_solution": "import re\nfrom urllib.parse import urlparse\nfrom bs4 import BeautifulSoup\nimport requests\n\ndef task_func(myString):\n    url = re.search(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', myString)\n    if url:\n        title = re.search(r'<title>(.*?)</title>', myString, re.DOTALL)\n        if title:\n            return title.group(1)\n        else:\n            return \"No title tag found in the webpage.\"\n    else:\n        return \"No valid URL found in the provided string.\"\n```"}
{"task_id": "BigCodeBench/1129", "solution": "import json\nimport requests\nimport os\nfrom datetime import datetime\ndef task_func(json_data, unknown_key, save_dir=None):\n    url = json_data['url']\n    filename = f'{unknown_key}_{datetime.now().strftime(\"%Y%m%d%H%M%S%f\")}.txt'\n    response = requests.get(url)\n    with open(os.path.join(save_dir, filename), 'wb') as f:\n        f.write(response.content)\n    return filename", "raw_solution": "import json\nimport requests\nimport os\nfrom datetime import datetime\n\ndef task_func(json_data, unknown_key, save_dir=None):\n    url = json_data['url']\n    filename = f'{unknown_key}_{datetime.now().strftime(\"%Y%m%d%H%M%S%f\")}.txt'\n    response = requests.get(url)\n    with open(os.path.join(save_dir, filename), 'wb') as f:\n        f.write(response.content)\n    return filename"}
{"task_id": "BigCodeBench/1137", "solution": "import bs4\nimport requests\nimport re\nimport json\ndef task_func(url: str, output_path: str) -> list:\n    soup = bs4.BeautifulSoup(requests.get(url).text, 'html.parser')\n    phone_numbers = re.findall(r'\\b\\d{3}-\\d{3}-\\d{4}\\b', soup.text)\n    with open(output_path, 'w') as f:\n        json.dump(phone_numbers, f)\n    return phone_numbers", "raw_solution": "import bs4\nimport requests\nimport re\nimport json\n\ndef task_func(url: str, output_path: str) -> list:\n    soup = bs4.BeautifulSoup(requests.get(url).text, 'html.parser')\n    phone_numbers = re.findall(r'\\b\\d{3}-\\d{3}-\\d{4}\\b', soup.text)\n    with open(output_path, 'w') as f:\n        json.dump(phone_numbers, f)\n    return phone_numbers"}
